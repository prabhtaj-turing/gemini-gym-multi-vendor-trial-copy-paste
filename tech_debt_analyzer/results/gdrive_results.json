{
  "analysis_timestamp": "2025-08-13T12:09:57.504445Z",
  "results": {
    "gdrive/Files.py": {
      "functions": {
        "copy": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a generally good overview of the function's purpose and usage.  It accurately describes the function's primary task: creating a copy of a file.  The Args section is comprehensive, listing all parameters with their types and descriptions, including default values and explanations.  The Returns section adequately describes the structure of the returned dictionary, although it could benefit from being more concise. The description of the `permissions` dictionary within both the Args and Returns sections is quite detailed and helpful.  The Raises section correctly lists potential exceptions.  Types are specified for all parameters and return values."
          },
          "pydantic_usage": {
            "status": "Partially Used",
            "notes": "The function uses a Pydantic model (`FileCopyBodyModel`) to validate the `body` parameter. This is good practice for complex, nested data structures. However, other parameters (fileId, ignoreDefaultVisibility, keepRevisionForever, ocrLanguage, supportsAllDrives, supportsTeamDrives, includePermissionsForView, includeLabels) are validated using basic type checking and value checks (e.g., checking for empty strings). While this provides some validation, it's less robust than using Pydantic models.  Pydantic models could be created for these parameters to provide more comprehensive validation, including constraints like string length or allowed values for enums.  For example, a Pydantic model could enforce that `ocrLanguage` is a valid language code from a predefined set.  Using Pydantic models consistently would improve the robustness and maintainability of the input validation."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function demonstrates good input validation for most functional parameters.  `fileId` receives both type and value validation (checking for emptiness and whitespace).  Boolean parameters (`ignoreDefaultVisibility`, `keepRevisionForever`, `supportsAllDrives`, `supportsTeamDrives`) are all checked for correct type. String parameters (`ocrLanguage`, `includePermissionsForView`, `includeLabels`) are also type-checked. The `body` parameter is checked for type and further validated using a Pydantic model (`FileCopyBodyModel`), which presumably handles more complex validation within its definition (though the details of that model are not provided)."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters are properly type-annotated with their expected types, including the use of Optional and Dict annotations to specify complex types.  The function's return type is clearly specified as `Dict[str, Any]`. No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely implements its intended functionality: it copies a file, handles quota checks, and allows for various customization options.  The core logic for copying and updating the DB is present. However, the `includePermissionsForView` and `includeLabels` parameters, while used, don't fully reflect the docstring's description. The docstring suggests these parameters influence permissions and labels directly, implying a more integrated change to the copied file's structure.  Instead, the implementation adds these as new top-level keys (`additionalPermissions` and `labels`) in the copied file.  This is a minor discrepancy, but it doesn't perfectly align with the docstring's implied behavior.  The deep copy logic is also improved but could be further refined for more complex nested structures."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `copy` function does not handle phone numbers or email addresses as input.  Its inputs are related to file metadata (file IDs, names, permissions, etc.) within a file storage system.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "create": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           enforceSingleParent: Optional[bool] = False,\n           ignoreDefaultVisibility: Optional[bool] = False,\n           keepRevisionForever: Optional[bool] = False,\n           ocrLanguage: Optional[str] = '',\n           supportsAllDrives: Optional[bool] = False,\n           supportsTeamDrives: Optional[bool] = False,\n           useContentAsIndexableText: Optional[bool] = False,\n           includePermissionsForView: Optional[str] = '',\n           includeLabels: Optional[str] = '',\n           ) -> Dict[str, Any]:\n    \"\"\"Creates a new file or folder with permissions if quota allows.\n\n    Args:\n        body (Optional[Dict[str, Any]]): Dictionary of file properties with keys:\n            - 'name' (str): Name of the file.\n            - 'mimeType' (str): MIME type of the file. Can be:\n                - 'application/vnd.google-apps.document'\n                - 'application/vnd.google-apps.spreadsheet'\n                - 'application/vnd.google-apps.presentation'\n                - 'application/vnd.google-apps.drawing'\n                - 'application/vnd.google-apps.folder'\n                - 'application/vnd.google-apps.script'\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'size' (str): File size in bytes (string that must be convertible to integer).\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects with keys:\n                - 'id' (str): Permission ID\n                - 'role' (str): Permission role (e.g., 'owner', 'reader', 'writer')\n                - 'type' (str): Permission type (e.g., 'user', 'group', 'domain', 'anyone')\n                - 'emailAddress' (str): Email address for user/group permissions\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent. Defaults to False.\n        ignoreDefaultVisibility (Optional[bool]): Whether to ignore default visibility. Defaults to False.\n        keepRevisionForever (Optional[bool]): Whether to keep revision forever. Defaults to False.\n        ocrLanguage (Optional[str]): The language to use for OCR. Defaults to empty string.\n        supportsAllDrives (Optional[bool]): Whether to support all drives. Defaults to False.\n        supportsTeamDrives (Optional[bool]): Whether to support team drives. Defaults to False.\n        useContentAsIndexableText (Optional[bool]): Whether to use content as indexable text. Defaults to False.\n        includePermissionsForView (Optional[str]): Specifies which additional view's permissions to include. Defaults to empty string.\n        includeLabels (Optional[str]): Comma-separated list of labels to include. Defaults to empty string.\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'driveId' (str): Shared drive ID if applicable.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file or folder.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file.\n            - 'sha1Checksum' (str): SHA1 checksum of the file.\n            - 'sha256Checksum' (str): SHA256 checksum of the file.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was uploaded). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was uploaded). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n            - 'enforceSingleParent' (bool): Single parent enforcement setting.\n            - 'ignoreDefaultVisibility' (bool): Default visibility setting.\n            - 'keepRevisionForever' (bool): Revision retention setting.\n            - 'ocrLanguage' (str): OCR language setting.\n            - 'supportsAllDrives' (bool): All drives support setting.\n            - 'supportsTeamDrives' (bool): Team drives support setting.\n            - 'useContentAsIndexableText' (bool): Content indexing setting.\n            - 'includePermissionsForView' (str): View permissions setting.\n            - 'includeLabels' (str): Labels setting.\n            - 'revisionSettings' (Dict[str, Any]): Revision settings with keys:\n                - 'keepForever' (bool): Whether to keep revisions forever\n            - 'ocrMetadata' (Dict[str, Any]): OCR metadata with keys:\n                - 'ocrLanguage' (str): OCR language code\n                - 'ocrStatus' (str): OCR processing status\n            - 'indexableText' (str): Extracted indexable text content.\n            - 'additionalPermissions' (List[Dict[str, Any]]): Additional view permissions.\n            - 'labels' (List[str]): List of parsed labels.\n            \n            Additional keys for specific MIME types:\n            For 'application/vnd.google-apps.spreadsheet':\n            - 'sheets' (List[Dict[str, Any]]): List of sheet objects with properties\n            - 'data' (Dict[str, Any]): Spreadsheet data\n            \n            For 'application/vnd.google-apps.document':\n            - 'content' (List[Any]): Document content\n            - 'tabs' (List[Any]): Document tabs\n            - 'suggestionsViewMode' (str): Suggestions view mode\n            - 'includeTabsContent' (bool): Whether to include tabs content\n\n    Raises:\n        TypeError: If 'body' is provided and is not a dictionary.\n        TypeError: If 'media_body' is provided and is not a dictionary.\n        TypeError: If 'enforceSingleParent', 'ignoreDefaultVisibility', 'keepRevisionForever',\n                   'supportsAllDrives', 'supportsTeamDrives', or 'useContentAsIndexableText'\n                   are not booleans.\n        TypeError: If 'ocrLanguage', 'includePermissionsForView', or 'includeLabels' are not strings.\n        ValidationError: If 'body' is provided and its structure or data types\n                                  do not conform to FileBodyModel.\n        ValidationError: If 'media_body' is provided and its structure or data types\n                                  do not conform to MediaBodyModel.\n        KeyError: If internal user lookup fails (propagated from _ensure_user or _get_user_quota).\n        ValueError: If body.get('size') is provided but its string value cannot be converted to an integer\n                    (e.g., \"abc\" instead of \"123\"). This is raised by the core logic.\n        QuotaExceededError: If the storage quota would be exceeded by creating the file.\n        FileNotFoundError: If media_body contains a filePath that doesn't exist.\n    \"\"\"\n    # --- Input Validation ---\n    if body is not None and not isinstance(body, dict):\n        raise TypeError(f\"Argument 'body' must be a dictionary or None, got {type(body).__name__}\")\n\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if body is not None:\n        try:\n            _ = FileBodyModel(**body)\n        except ValidationError as e:\n            raise e\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Standard type validation for other arguments\n    bool_args = {\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText\n    }\n    for arg_name, arg_val in bool_args.items():\n        if not isinstance(arg_val, bool):\n            raise TypeError(f\"Argument '{arg_name}' must be a boolean, got {type(arg_val).__name__}\")\n\n    str_args = {\n        'ocrLanguage': ocrLanguage,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels\n    }\n    for arg_name, arg_val in str_args.items():\n        if not isinstance(arg_val, str):\n            raise TypeError(f\"Argument '{arg_name}' must be a string, got {type(arg_val).__name__}\")\n\n    userId = 'me'\n    _ensure_user(userId)\n    processed_body = {} if body is None else body\n    \n    # Check if this is a Google Workspace document type\n    mime_type = processed_body.get('mimeType', 'application/octet-stream')\n    google_workspace_mime_types = {\n        'application/vnd.google-apps.document',\n        'application/vnd.google-apps.spreadsheet',\n        'application/vnd.google-apps.presentation',\n        'application/vnd.google-apps.drawing',\n        'application/vnd.google-apps.form'\n    }\n    \n    if mime_type in google_workspace_mime_types:\n        # Use DriveFileProcessor to create Google Workspace document\n        processor = DriveFileProcessor()\n        \n        # Map MIME type to document type\n        mime_to_doc_type = {\n            'application/vnd.google-apps.document': 'google_docs',\n            'application/vnd.google-apps.spreadsheet': 'google_sheets',\n            'application/vnd.google-apps.presentation': 'google_slides',\n            'application/vnd.google-apps.drawing': 'google_drawings',\n            'application/vnd.google-apps.form': 'google_forms'\n        }\n        \n        doc_type = mime_to_doc_type[mime_type]\n        new_file = processor.create_google_workspace_document(doc_type)\n        \n        # Update with user-specific data\n        user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n        new_file['owners'] = [user_email]\n        new_file['permissions'] = []\n        \n        # Apply name from body if provided\n        if 'name' in processed_body:\n            new_file['name'] = processed_body['name']\n        \n        # Apply parents from body if provided\n        if 'parents' in processed_body:\n            new_file['parents'] = processed_body['parents']\n        \n        # Apply permissions from body if provided\n        if 'permissions' in processed_body:\n            new_file['permissions'] = processed_body['permissions']\n        elif not ignoreDefaultVisibility:\n            # Add default owner permission\n            new_file['permissions'].append({\n                'id': 'permission_' + new_file['id'],\n                'role': 'owner',\n                'type': 'user',\n                'emailAddress': user_email\n            })\n        \n        # Add additional parameters\n        new_file.update({\n            'enforceSingleParent': enforceSingleParent,\n            'ignoreDefaultVisibility': ignoreDefaultVisibility,\n            'keepRevisionForever': keepRevisionForever,\n            'ocrLanguage': ocrLanguage,\n            'supportsAllDrives': supportsAllDrives,\n            'supportsTeamDrives': supportsTeamDrives,\n            'useContentAsIndexableText': useContentAsIndexableText,\n            'includePermissionsForView': includePermissionsForView,\n            'includeLabels': includeLabels,\n            'revisionSettings': {'keepForever': keepRevisionForever},\n            'ocrMetadata': {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'} if ocrLanguage else {},\n            'indexableText': '',\n            'additionalPermissions': [],\n            'labels': [label.strip() for label in includeLabels.split(',') if label.strip()] if includeLabels else []\n        })\n        \n        # Save the file and return\n        FileWithContentModel(**new_file)\n        DB['users'][userId]['files'][new_file['id']] = new_file\n        return new_file\n    \n    # Continue with regular file creation logic for non-Google Workspace files\n    file_size = int(processed_body.get('size', '0'))\n    quota = _get_user_quota(userId)\n\n    # Handle content upload from media_body\n    content_data = None\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Handle content upload - check for actual file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Create content data using file_data, adding missing fields\n            content_data = {\n                'data': file_data['content'] if file_data['encoding'] == 'text' else file_data['content'],\n                'encoding': file_data['encoding'],\n                'checksum': DriveFileProcessor().calculate_checksum(\n                    file_data['content'].encode('utf-8') if file_data['encoding'] == 'text' \n                    else decode_from_base64(file_data['content'])\n                ),\n                'version': '1.0',\n                'lastContentUpdate': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n            }\n            file_size = file_data['size_bytes']\n            \n            # Update file metadata from media_body\n            processed_body['size'] = str(file_size)\n            processed_body['md5Checksum'] = validated_media_body.md5Checksum or ''\n            processed_body['sha1Checksum'] = validated_media_body.sha1Checksum or ''\n            processed_body['sha256Checksum'] = validated_media_body.sha256Checksum or ''\n            processed_body['mimeType'] = validated_media_body.mimeType or processed_body.get('mimeType', 'application/octet-stream')\n            processed_body['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or {}\n            processed_body['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or {}\n\n    # Quota check before creating\n    if quota['usage'] + file_size > quota['limit']:\n        raise QuotaExceededError(\"Quota exceeded. Cannot create the file.\")\n\n    file_id_num = _next_counter('file')  # Assumed to exist\n    file_id = f\"file_{file_id_num}\"\n    user_email = DB['users'][userId]['about'].get('user', {}).get('emailAddress', 'user@example.com')\n\n    # Handle enforceSingleParent\n    parents = processed_body.get('parents', [])\n    if enforceSingleParent and len(parents) > 1:\n        parents = [parents[-1]]\n\n    # Handle ignoreDefaultVisibility\n    default_permissions_list = []\n    if not ignoreDefaultVisibility:\n        default_permissions_list.append({\n            'id': 'permission_' + file_id,\n            'role': 'owner',\n            'type': 'user',\n            'emailAddress': user_email\n        })\n\n    # Handle keepRevisionForever\n    revision_settings = {'keepForever': keepRevisionForever}\n\n    # Handle OCR language if specified\n    ocr_metadata = {}\n    if ocrLanguage:\n        ocr_metadata = {'ocrLanguage': ocrLanguage, 'ocrStatus': 'PENDING'}\n\n    # Handle content indexing\n    indexable_text = ''\n    if useContentAsIndexableText and 'filePath' in media_body:\n        indexable_text = 'Extracted text from content'\n\n    # Handle additional permissions for view\n    additional_permissions_for_view = []\n    if includePermissionsForView:\n        # In a real implementation, this would fetch additional permissions\n        additional_permissions_for_view.append({\n            'id': 'view_' + file_id, 'role': 'reader', 'type': 'anyone'\n        })\n\n    # Handle labels\n    parsed_labels = []\n    if includeLabels:\n        parsed_labels = [label.strip() for label in includeLabels.split(',') if label.strip()]\n\n    # Create base file structure with additional parameters\n    new_file: Dict[str, Any] = {\n        'kind': 'drive#file',\n        'id': file_id,\n        'driveId': '',\n        'name': processed_body.get('name', f'File_{file_id_num}'),\n        'mimeType': processed_body.get('mimeType', 'application/octet-stream'),\n        'parents': parents,\n        'createdTime': processed_body.get('createdTime', '2025-03-14T00:00:00Z'),\n        'modifiedTime': processed_body.get('modifiedTime', '2025-03-14T00:00:00Z'),\n        'trashed': False,\n        'starred': processed_body.get('starred', False),\n        'owners': [user_email],\n        'size': str(file_size),\n        'md5Checksum': processed_body.get('md5Checksum', ''),\n        'sha1Checksum': processed_body.get('sha1Checksum', ''),\n        'sha256Checksum': processed_body.get('sha256Checksum', ''),\n        'imageMediaMetadata': processed_body.get('imageMediaMetadata', {}),\n        'videoMediaMetadata': processed_body.get('videoMediaMetadata', {}),\n        'permissions': default_permissions_list,\n        # Additional parameters\n        'enforceSingleParent': enforceSingleParent,\n        'ignoreDefaultVisibility': ignoreDefaultVisibility,\n        'keepRevisionForever': keepRevisionForever,\n        'ocrLanguage': ocrLanguage,\n        'supportsAllDrives': supportsAllDrives,\n        'supportsTeamDrives': supportsTeamDrives,\n        'useContentAsIndexableText': useContentAsIndexableText,\n        'includePermissionsForView': includePermissionsForView,\n        'includeLabels': includeLabels,\n        'revisionSettings': revision_settings,\n        'ocrMetadata': ocr_metadata,\n        'indexableText': indexable_text,\n        'additionalPermissions': additional_permissions_for_view,\n        'labels': parsed_labels\n    }\n\n    # Handle content upload and storage\n    if content_data:\n        # Add content to file\n        new_file['content'] = content_data\n        new_file['revisions'] = []\n        \n        # Create initial revision if content was uploaded\n        if content_data.get('data'):\n            revision_id = f\"rev-1\"\n            \n            # Create revision content with only the 3 required fields for RevisionContentModel\n            revision_content = {\n                'data': content_data['data'],\n                'encoding': content_data['encoding'],\n                'checksum': content_data['checksum']\n            }\n            \n            revision = {\n                'id': revision_id,\n                'mimeType': new_file['mimeType'],\n                'modifiedTime': datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'keepForever': keepRevisionForever,\n                'originalFilename': new_file['name'],\n                'size': str(file_size),\n                'content': revision_content\n            }\n            RevisionModel(**revision)\n            new_file['revisions'].append(revision)\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.spreadsheet':\n        new_file['sheets'] = [\n            {\n                'properties': {\n                    'sheetId': 'sheet1',\n                    'title': 'Sheet1',\n                    'index': 0,\n                    'sheetType': 'GRID',\n                    'gridProperties': {\n                        'rowCount': 1000,\n                        'columnCount': 26\n                    }\n                }\n            }\n        ]\n        new_file['data'] = {}\n\n    if processed_body.get('mimeType') == 'application/vnd.google-apps.document':\n        new_file['content'] = []\n        new_file['tabs'] = []\n        new_file['suggestionsViewMode'] = 'DEFAULT'\n        new_file['includeTabsContent'] = False\n\n    # Handle permissions override from 'body' - FIXED: Prevent double owner permission\n    if 'permissions' in processed_body:\n        final_permissions = []\n        for perm_dict in processed_body['permissions']:\n            if perm_dict['type'] == 'user' and not perm_dict.get('emailAddress'):\n                continue\n            final_permissions.append(perm_dict)\n        new_file['permissions'] = final_permissions\n    else:\n        # Only add default owner permission if ignoreDefaultVisibility was True\n        if ignoreDefaultVisibility:\n            new_file['permissions'].append({\n                'id': 'permission_' + file_id, 'role': 'owner', 'type': 'user', 'emailAddress': user_email\n            })\n    FileWithContentModel(**new_file)\n    DB['users'][userId]['files'][file_id] = new_file\n    _update_user_usage(userId, file_size)\n    return new_file\n\n"
          }
        },
        "delete": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's main task: permanently deleting a file. The Args section correctly lists all parameters with their types and descriptions, including default values. The Returns section accurately states that the function returns None. The Raises section correctly lists the potential exceptions.  Types are specified for all parameters and the return value."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking for all its functional input parameters (`fileId`, `enforceSingleParent`, `supportsAllDrives`, `supportsTeamDrives`).  While Pydantic could provide a more structured and potentially more extensible approach, the existing manual checks adequately ensure that the inputs are of the correct type.  The addition of Pydantic would be an improvement in terms of code organization and potential for future expansion of validation rules, but it's not strictly necessary given the current implementation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive type validation on all four functional input parameters (`fileId`, `enforceSingleParent`, `supportsAllDrives`, and `supportsTeamDrives`).  It checks that `fileId` is a string and the boolean parameters are booleans. While there isn't explicit value validation (e.g., checking for a specific format in `fileId`), the subsequent code implicitly validates `fileId` by attempting to retrieve the file from the database and raising a `FileNotFoundError` if it doesn't exist. This acts as a form of value validation within the context of the application.  All functional parameters are checked before being used in the function's logic.  The error handling is also robust, raising specific exceptions with informative messages."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, enforceSingleParent, supportsAllDrives, supportsTeamDrives) are properly type-annotated with their expected types (str, Optional[bool], Optional[bool], Optional[bool] respectively). The function's return type is clearly specified as None.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the deletion of a file, handling various scenarios including shared drives, multiple parents, and folder deletion.  All functional input parameters (`fileId`, `enforceSingleParent`) are used appropriately in the logic.  The documented exceptions (`TypeError`, `FileNotFoundError`, `PermissionError`) are all properly raised in relevant situations. There are no TODOs, placeholders, or pass statements. The docstring accurately reflects the function's behavior and return type.  The logic is complete and functional given the use of the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code does not handle any phone number or email address inputs.  It deals exclusively with file IDs, user IDs, and other data related to a file deletion operation within a system (likely a cloud storage system).  Therefore, the criteria of phone number normalization and email validation are not applicable."
          }
        },
        "emptyTrash": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a reasonable description of the function's purpose.  It correctly lists all parameters with their types and includes descriptions. The `Args` section is well-structured. The docstring accurately reflects that the function permanently deletes trashed files.  The return type (`-> None`) is correctly specified.  However, the docstring does not mention that the function currently has no actual implementation beyond a placeholder `pass` statement.  This is a significant omission, as a user might expect files to be deleted based on the docstring, but the function does nothing.  Also, while default values are mentioned in the parameter list, they are not explicitly explained in the docstring.  Adding a sentence explaining the implications of each parameter's default value (e.g., \"If `driveId` is not specified, the trash for the user's default drive will be emptied.\") would improve clarity.  Finally, there's no mention of potential exceptions (e.g., network errors, authorization failures), which should be included in a \"Raises\" section for completeness."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function `emptyTrash` does not use Pydantic models or any other form of input validation for its functional parameters (`driveId`, `enforceSingleParent`, `supportsAllDrives`, `supportsTeamDrives`).  While type hints are present, they are not enforced.  Adding Pydantic models would significantly improve the robustness of the function by ensuring that the input data conforms to the expected types and potentially adding more sophisticated validation rules (e.g., length restrictions on `driveId`)."
          },
          "input_validation": {
            "status": "Minimal",
            "notes": "The function has minimal input validation.  `driveId` is the only functional parameter, and it receives no validation whatsoever; no type checking, no empty string check, and no value validation (e.g., checking if it's a valid drive ID format).  The boolean parameters (`enforceSingleParent`, `supportsAllDrives`, `supportsTeamDrives`) are not validated at all.  No exceptions are raised for invalid inputs.  Therefore, the validation is minimal."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (driveId, enforceSingleParent, supportsAllDrives, supportsTeamDrives) are properly type-annotated with their expected types (str, bool, bool, bool respectively). The function's return type is clearly specified as None.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Stub",
            "notes": "The function uses a placeholder comment (`pass`) and does not actually implement the core functionality of permanently deleting trashed files.  While it correctly identifies the user ID, it lacks any interaction with a database (even the mock `DB` dictionary) to locate and delete trashed files.  The `driveId`, `enforceSingleParent`, `supportsAllDrives`, and `supportsTeamDrives` parameters are not used in the function's logic.  The docstring promises to permanently delete trashed files, but the implementation does not fulfill this promise."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `emptyTrash` function does not handle any phone number or email address inputs.  Its parameters are related to Google Drive management (drive IDs, flags for drive support), and therefore, the criteria for phone number normalization and email validation are not applicable.  The function's purpose is to empty a trash can in a file system, not to process contact information."
          }
        },
        "export": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and behavior.  It accurately describes the function's arguments and their types, and it correctly details the structure of the dictionary returned. The `Raises` section is comprehensive, listing all potential exceptions.  Type hints are used effectively throughout the docstring."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `fileId` and `mimeType` parameters.  It checks that they are strings and that they are not empty or whitespace-only.  While Pydantic could provide a more concise and potentially more feature-rich way to perform this validation (e.g., handling different error types more elegantly), the existing validation is sufficient and covers all functional input parameters.  Using Pydantic here would be an unnecessary addition."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive input validation for both `fileId` and `mimeType`.  Both parameters are checked for correct type (string) using `isinstance`.  Furthermore, both undergo value validation, ensuring they are not empty or whitespace-only strings using `if not fileId or not fileId.strip()`.  Appropriate `TypeError` and `ValueError` exceptions are raised with clear error messages for invalid inputs.  All functional input parameters are validated before being used in the export process."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "Both function parameters, `fileId` and `mimeType`, are properly type-annotated as strings.  The return type is clearly specified as `Dict[str, Any]`.  The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional.  It correctly handles the input validation as documented, uses both `fileId` and `mimeType` parameters, and raises the specified exceptions (`TypeError`, `ValueError`). The core export logic is delegated to `DriveContentManager.export_file_content`, which is assumed to be correctly implemented.  The return dictionary matches the docstring's specification. However, the exception handling within the `try...except` block could be improved.  Currently, it simply re-raises the `ValueError` without adding any context or logging.  More robust error handling might involve logging the error or adding more specific error messages to aid debugging.  Additionally, the `_ensure_user` function is called but its implementation is not shown, so its potential impact on completeness cannot be fully assessed.  A missing or improperly implemented `_ensure_user` could lead to issues."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `export` does not handle any phone numbers or email addresses.  Its inputs are a file ID and a MIME type, both strings.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function correctly validates that the fileId and mimeType are non-empty strings, which is appropriate for its purpose."
          }
        },
        "generateIds": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a decent overview of the function's purpose.  It accurately describes the function's primary task: generating file IDs. The Args section correctly lists and describes the parameters, including their default values. The Returns section correctly specifies the dictionary structure and types, including the nested list of IDs.  Type hints are used consistently throughout the docstring."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function `generateIds` does not use Pydantic models for input validation.  It also lacks any other form of input validation for the `count` and `space` parameters.  While `count` is annotated as an `int`, this is only a type hint and does not enforce validation (e.g., preventing negative values). The `space` parameter has no validation at all.  Using a Pydantic model would significantly improve the robustness of this function by ensuring that the inputs are of the correct type and within acceptable ranges."
          },
          "input_validation": {
            "status": "Partial",
            "notes": "The function `generateIds` has two functional input parameters: `count` and `space`.  `count` is validated implicitly by its type annotation (`int`), but lacks explicit value validation.  A negative `count` would lead to an empty list of IDs, which might be unexpected behavior but doesn't cause an error. There's no check to ensure `count` is a non-negative integer. The `space` parameter is only used in the `_next_counter` function (not shown), and there is no validation performed on it within `generateIds` itself.  Therefore, while there is some implicit type validation, crucial value validation is missing for both parameters.  No explicit null or empty checks are present.  No error handling is implemented for invalid inputs."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "Both function parameters (`count` and `space`) are properly type-annotated with `int` and `str` respectively.  The return type is clearly specified as `Dict[str, Any]`. The function does not use `**kwargs`.  All type annotations are complete and accurate."
          },
          "implementation_status": {
            "status": "Partially Complete",
            "notes": "The function is missing a definition for the `_next_counter` function.  Without knowing its implementation, it's impossible to determine if the ID generation is truly unique or correctly handles potential errors. The `space` parameter is a functional parameter that is not used in the function's logic.  The docstring correctly describes the return type, but the actual implementation's correctness depends on the undefined `_next_counter` function."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `generateIds` does not handle phone numbers or email addresses as input.  It generates file IDs based on a counter and a specified space. Therefore, the criteria of phone number normalization and email validation are not applicable.  The function's purpose is entirely different."
          }
        },
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and behavior.  It accurately describes the function's arguments and return value, including types. The documentation of the nested dictionary structures within the return value (`content` and `revisions`) is thorough and helpful.  The `Raises` section correctly lists the exceptions.  Type hints are used effectively."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `fileId` parameter.  It checks if `fileId` is None, if it's a string, and if it contains any non-whitespace characters.  While Pydantic could be used, the current manual validation is sufficient and correctly handles the potential issues.  Using Pydantic wouldn't add significant value in this simple case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get` has one functional input parameter: `fileId`.  The input validation comprehensively checks this parameter.  Specifically:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get` has excellent parameter design.  The single parameter `fileId` is correctly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` are used.  All type annotations are complete and accurate."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly retrieves file metadata from the global `DB` based on the provided `fileId`.  All functional input parameters (`fileId`) are used.  The documented exceptions (`TypeError`, `ValueError`, `FileNotFoundError`) are all properly implemented. There are no TODOs, pass statements, or placeholder implementations. The function's logic is complete and functional given the use of the global `DB`. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle any phone number or email address inputs.  Its purpose is to retrieve file metadata from a database given a file ID.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function does include robust input validation for the `fileId` parameter itself, checking for `None`, correct type, and empty strings, which is good practice."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's core functionality: listing files with support for shared drives, ordering, and pagination.  The Args section is comprehensive, documenting all parameters with types and descriptions, including default values and explanations. The Returns section correctly specifies the dictionary structure, although it could benefit from more detail on the nested `files` list's structure (e.g., specifying the keys and types within each file metadata object). The Raises section lists the potential exceptions.  Types are specified for all parameters and the return value."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for all functional parameters.  It checks the types of the parameters and performs additional validation specific to the parameter's purpose (e.g., checking if `pageSize` is positive, validating the format of `corpora`, `spaces`, `orderBy`, and `includeLabels`, and performing basic syntax checks on the `q` parameter). While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing manual approach is comprehensive and covers all functional parameters.  Using Pydantic would not significantly improve the validation in this case, and the current method is perfectly adequate."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "All functional input parameters are checked for their correct data types using `isinstance`.  Furthermore, value validation is performed on several parameters:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters are properly type-annotated with their expected types (using Optional for optional parameters and specifying complex types like List[Dict[str, Any]] where appropriate). The function's return type is clearly specified as `Dict[str, Any]`.  The function does not use `**kwargs` parameters."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional, correctly using most of the functional input parameters.  However, the `includePermissionsForView` parameter's logic is incomplete; it only checks for the existence of permissions of a certain type, not necessarily the permissions relevant to the view type.  The implementation of pagination using `pageToken` is also rudimentary; a more robust token generation and decoding mechanism would be needed for production use.  The query string parsing (`_parse_query` and `_apply_query_filter` - assumed to exist elsewhere) is not directly evaluated here, but its correctness is crucial for the function's overall functionality.  Finally, error handling beyond type checking is minimal; more robust error handling (e.g., for database access issues) would improve the function's reliability."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle phone numbers or email addresses as input.  Its purpose is to list files from a Google Drive-like system, using various parameters for filtering and pagination.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "update": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'update': def update(fileId: str,\n           body: Optional[Dict[str, Any]] = None,\n           media_body: Optional[Dict[str, Any]] = None,\n           addParents: Optional[str] = '',\n           enforceSingleParent: Optional[bool] = False,\n           removeParents: Optional[str] = '',\n           ) -> Optional[Dict[str, Any]]:\n    \"\"\" \n    Updates a file's metadata or content with patch semantics. \n    \n    This means only the fields explicitly provided in the `body` dictionary\n    will be updated. All other file properties will remain unchanged.\n\n    Args:\n        fileId (str): The ID of the file to update.\n        body (Optional[Dict[str, Any]]): Dictionary of file properties to update with keys:\n            - 'name' (str): New name of the file.\n            - 'mimeType' (str): New MIME type of the file.\n            - 'parents' (List[str]): New list of parent folder IDs.\n            - 'permissions' (List[Dict[str, Any]]): New list of permission objects.\n        media_body (Optional[Dict[str, Any]]): Dictionary containing media content properties to update with keys:\n            - 'size' (int): File size in bytes.\n            - 'md5Checksum' (str): MD5 checksum of the file content.\n            - 'sha1Checksum' (str): SHA1 checksum of the file content.\n            - 'sha256Checksum' (str): SHA256 checksum of the file content.\n            - 'mimeType' (str): MIME type of the file content.\n            - 'imageMediaMetadata' (Dict[str, Any]): Metadata for image files.\n            - 'videoMediaMetadata' (Dict[str, Any]): Metadata for video files.\n            - 'filePath' (str): Path to file for content upload (creates new revision).\n        addParents (Optional[str]): Comma-separated list of parent IDs to add, defaults to ''.\n        enforceSingleParent (Optional[bool]): Whether to enforce single parent, defaults to False.\n        removeParents (Optional[str]): Comma-separated list of parent IDs to remove, defaults to ''.\n\n    Returns:\n        Optional[Dict[str, Any]]: Dictionary containing the updated file with keys:\n            - 'kind' (str): Resource type identifier (e.g., 'drive#file').\n            - 'id' (str): File ID.\n            - 'name' (str): File name.\n            - 'mimeType' (str): MIME type of the file.\n            - 'parents' (List[str]): List of parent folder IDs.\n            - 'createdTime' (str): Creation timestamp.\n            - 'modifiedTime' (str): Last modification timestamp.\n            - 'trashed' (bool): Whether the file is in trash.\n            - 'starred' (bool): Whether the file is starred.\n            - 'owners' (List[str]): List of owner email addresses.\n            - 'size' (str): File size in bytes.\n            - 'permissions' (List[Dict[str, Any]]): List of permission objects.\n            - 'content' (Dict[str, Any]): File content with metadata (if content was updated). Contains:\n                - 'data' (str): Text or Base64 encoded content data\n                - 'encoding' (str): Content encoding ('text' or 'base64')\n                - 'checksum' (str): SHA256 checksum for integrity verification\n                - 'version' (str): Content version\n                - 'lastContentUpdate' (str): Timestamp of last content update\n            - 'revisions' (List[Dict[str, Any]]): List of file revisions (if content was updated). Contains:\n                - 'id' (str): Revision ID\n                - 'mimeType' (str): MIME type of the revision\n                - 'modifiedTime' (str): When the revision was created\n                - 'keepForever' (bool): Whether to keep this revision forever\n                - 'originalFilename' (str): Original filename\n                - 'size' (str): File size in bytes\n                - 'content' (Dict[str, Any]): Revision content with metadata. Contains:\n                    - 'data' (str): Text or Base64 encoded content data\n                    - 'encoding' (str): Content encoding ('text' or 'base64')\n                    - 'checksum' (str): SHA256 checksum for integrity verification\n\n    Raises:\n        TypeError: If `fileId`, `addParents`, `removeParents` are not strings,\n                   or if `enforceSingleParent` is not a boolean, or if `media_body` \n                   is provided and is not a dictionary.\n        ResourceNotFoundError: If the file with the specified `fileId` is not found.\n        ValidationError: If `body` is provided and does not conform to the\n                                 expected structure (UpdateBodyModel), or if `media_body`\n                                 is provided and does not conform to MediaBodyModel.\n        KeyError: (Propagated) If `userId` used internally (e.g., 'me') is not\n                  found by `_ensure_user` or during database access.\n        QuotaExceededError: If the storage quota would be exceeded by updating the file content.\n    \"\"\"\n    # --- Input Validation Start ---\n\n    # Validate non-dictionary arguments\n    if not isinstance(fileId, str):\n        raise TypeError(\"fileId must be a string.\")\n    if not isinstance(addParents, str):\n        raise TypeError(\"addParents must be a string.\")\n    if not isinstance(enforceSingleParent, bool):\n        raise TypeError(\"enforceSingleParent must be a boolean.\")\n    if not isinstance(removeParents, str):\n        raise TypeError(\"removeParents must be a string.\")\n\n    # Validate 'media_body' dictionary using Pydantic\n    if media_body is not None and not isinstance(media_body, dict):\n        raise TypeError(f\"Argument 'media_body' must be a dictionary or None, got {type(media_body).__name__}\")\n\n    if media_body is not None:\n        try:\n            validated_media_body = MediaBodyModel(**media_body)\n        except ValidationError as e:\n            raise e\n\n    # Validate 'body' dictionary using Pydantic\n    if body is not None:\n        if not isinstance(body, dict):  # Ensure body, if not None, is a dict before Pydantic\n            raise TypeError(\"body must be a dictionary if provided.\")\n        try:\n            validated_body_model = UpdateBodyModel(**body)\n            # For PATCH semantics, use exclude_unset=True to only include fields\n            # that were explicitly provided in the input.\n            body = validated_body_model.model_dump(exclude_unset=True)\n        except ValidationError as e:\n            raise e\n\n\n    userId = 'me'  # Assuming 'me' for now\n    _ensure_user(userId)\n\n    try:\n        existing = DB['users'][userId]['files'][fileId]\n    except KeyError:\n        raise ResourceNotFoundError(f\"File with ID '{fileId}' not found.\")\n    # --- Input Validation End ---\n\n    # --- Original Core Logic Start ---\n\n    if body is None:\n        body = {}\n\n    # Get the file to update\n    existing = DB['users'][userId]['files'].get(fileId)\n    if not existing:\n        return None\n\n    # Process media_body if provided to update file content\n    if media_body:\n        validated_media_body = MediaBodyModel(**media_body)\n        \n        # Calculate current file size for quota management\n        current_file_size = int(existing.get('size', '0'))\n        new_file_size = validated_media_body.size or current_file_size\n        \n        # Check quota before updating content\n        quota = _get_user_quota(userId)\n        size_difference = new_file_size - current_file_size\n        \n        if quota['usage'] + size_difference > quota['limit']:\n            raise QuotaExceededError(\"Quota exceeded. Cannot update the file content.\")\n\n        # Use content manager for content updates and revision handling\n        content_manager = DriveContentManager()\n        \n        # If filePath is provided, read the file content\n        if 'filePath' in media_body and isinstance(media_body['filePath'], str):\n            file_path = media_body['filePath']\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            # Use read_file function to properly read file content with encoding\n            file_data = read_file(file_path)\n            \n            # Convert content to bytes for content manager\n            if file_data['encoding'] == 'text':\n                new_content = file_data['content'].encode('utf-8')\n            else:\n                # For base64 encoded content, decode it to bytes\n                new_content = decode_from_base64(file_data['content'])\n            \n            # Use content manager to update file content (this handles revisions automatically)\n            content_manager.update_file_content(userId, fileId, new_content)\n            \n            # Update file metadata from media_body\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n        else:\n            # Update file metadata from media_body without content change\n            existing['size'] = str(new_file_size)\n            existing['md5Checksum'] = validated_media_body.md5Checksum or existing.get('md5Checksum', '')\n            existing['sha1Checksum'] = validated_media_body.sha1Checksum or existing.get('sha1Checksum', '')\n            existing['sha256Checksum'] = validated_media_body.sha256Checksum or existing.get('sha256Checksum', '')\n            if validated_media_body.mimeType:\n                existing['mimeType'] = validated_media_body.mimeType\n            existing['imageMediaMetadata'] = validated_media_body.imageMediaMetadata or existing.get('imageMediaMetadata', {})\n            existing['videoMediaMetadata'] = validated_media_body.videoMediaMetadata or existing.get('videoMediaMetadata', {})\n            \n            # Update user quota usage\n            _update_user_usage(userId, size_difference)\n            \n            # Update modified time to current timestamp\n            existing['modifiedTime'] = datetime.now(UTC).strftime('%Y-%m-%dT%H:%M:%SZ')\n\n    # Ensure 'parents' exists as a list\n    if 'parents' not in existing or not isinstance(existing['parents'], builtins.list):\n        existing['parents'] = []\n\n    # Handle addParents (comma-separated string of parent IDs)\n    if addParents:\n        add_parents_list = [p.strip() for p in addParents.split(',') if p.strip()]\n        for parent in add_parents_list:\n            if parent not in existing['parents']:\n                existing['parents'].append(parent)\n\n    # Handle removeParents (comma-separated string of parent IDs)\n    if removeParents:\n        remove_parents_list = [p.strip() for p in removeParents.split(',') if p.strip()]\n        existing['parents'] = [p for p in existing['parents'] if p not in remove_parents_list]\n\n    # If enforceSingleParent is True, only keep the last parent\n    if enforceSingleParent and existing['parents']:\n        existing['parents'] = [existing['parents'][-1]]\n\n    # Apply the patch update from body\n    existing.update(body)\n\n    return existing\n\n"
          }
        },
        "watch": {
          "docstring_quality": {
            "status": "Adequate",
            "notes": "The docstring is present and provides a reasonable overview of the function's purpose and arguments.  It correctly describes the `fileId`, `acknowledgeAbuse`, `ignoreDefaultVisibility`, `supportsAllDrives`, `supportsTeamDrives`, `includePermissionsForView`, and `includeLabels` parameters and their types. The description of the `body` parameter is also adequate, listing the potential keys.  The `Returns` section correctly identifies the return type as `Dict[str, Any]` and lists the expected keys.  Type hints are used consistently throughout."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function lacks any input validation using Pydantic models or other methods for the functional parameters.  `fileId` is declared as a string, but there's no check to ensure it's a valid file ID format or length. The `body` parameter, while optionally a dictionary, doesn't have its contents validated.  There's no check on the keys or types within the dictionary.  The boolean parameters (`acknowledgeAbuse`, `ignoreDefaultVisibility`, `supportsAllDrives`, `supportsTeamDrives`) are not explicitly validated, although Python's type hinting provides some basic type checking.  The string parameters (`includePermissionsForView`, `includeLabels`) also lack validation; there's no check to ensure they conform to any expected format.  Using Pydantic models would significantly improve the robustness of input validation by providing a structured and comprehensive approach to type checking and data validation."
          },
          "input_validation": {
            "status": "Partial",
            "notes": "The function performs type validation for `fileId` (implicitly as it's annotated as `str`) and `acknowledgeAbuse`, `ignoreDefaultVisibility`, `supportsAllDrives`, and `supportsTeamDrives` (implicitly as they are annotated as `bool`).  It also includes a null check for the `body` parameter. However, it lacks crucial value validation.  `fileId` should be checked for a valid file ID format (perhaps a regex check). The `body` dictionary, if not None, needs validation of its keys ('id', 'type', 'address', 'token', 'expiration') for correct types and non-empty values.  `includePermissionsForView` and `includeLabels` also require validation;  `includePermissionsForView` might need to be checked against an allowed set of values, and `includeLabels` should be checked for valid label formats (e.g., no injection vulnerabilities). There's no explicit error handling for invalid inputs; the code silently proceeds with potentially invalid data.  While type hints provide some level of validation, they are not enforced at runtime and do not constitute robust validation.  The function uses the `body` dictionary directly without verifying the presence or validity of its keys."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters are properly type-annotated with their expected types.  The return type is clearly specified as `Dict[str, Any]`. The function does not use `**kwargs`.  All complex types (Optional, Dict) are properly specified."
          },
          "implementation_status": {
            "status": "Partially Complete",
            "notes": "The function uses the `fileId` parameter in the key of the global `DB`, but it does not actually use the `acknowledgeAbuse`, `ignoreDefaultVisibility`, `supportsAllDrives`, `supportsTeamDrives`, `includePermissionsForView`, and `includeLabels` parameters.  These are functional parameters, not MCP contextual parameters, and their absence represents a significant gap in the implementation.  While the function simulates setting up a watch by storing data in the `DB`, it lacks the actual logic to create and manage a watch subscription. The docstring promises a return dictionary with specific keys (`kind`, `resourceId`, `resourceUri`), but the function returns the input `body` which may not contain these keys.  The function also makes assumptions about the structure of the `DB` which might not always be true.  The function's logic is a simplified simulation and not a complete implementation of a watch functionality."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `watch` function does not handle any phone number or email address inputs.  Its parameters and functionality relate to Google Drive file watching and channel management.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "get_content": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's core logic: retrieving file content, optionally specifying a revision. The Args, Returns, and Raises sections are present and generally well-structured.  Types are specified for parameters and return values.  The documentation of the nested dictionary structure within the `Returns` section is particularly helpful, clearly outlining the keys and types within the `content` dictionary."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking and value checks for the `user_id`, `file_id`, and `revision_id` parameters.  While Pydantic could be used to achieve the same validation more concisely, the existing manual checks are sufficient and cover all functional input parameters.  The use of Pydantic models later in the function to check the structure of data retrieved from the database is not related to input validation."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on `user_id`, `file_id`, and `revision_id`.  It also checks if the `user_id` and `file_id` exist in the `DB`. This is a form of value validation, ensuring that the IDs refer to existing entities.  However, it lacks checks for empty strings in `user_id` and `file_id`, which could be considered a gap.  The validation is good but not comprehensive due to this omission.  Additionally, while it checks for the existence of the file and revision, it doesn't validate the format or structure of the IDs themselves (e.g., length restrictions, allowed characters).  The error messages are clear and informative."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`user_id`, `file_id`, `revision_id`) are properly type-annotated with their expected types (str, str, Optional[str] respectively). The function's return type is clearly specified as `Dict[str, Any]`.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly retrieves file content, handling both cases with and without a revision ID.  All functional input parameters (`user_id`, `file_id`, `revision_id`) are used appropriately in the logic to fetch and return the correct data.  All documented exceptions (`ValueError` for various scenarios like user/file/revision not found, or missing content) are properly implemented. There are no TODOs, placeholders, or pass statements. The docstring accurately reflects the function's behavior, including the structure of the returned dictionary.  The logic is complete and functional given the use of the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get_content` does not handle any phone numbers or email addresses.  Its inputs and outputs are file IDs, revision IDs, and file content data. Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "create_revision": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's main task: creating a new revision for a file. The Args, Returns, and Raises sections are well-structured and mostly accurate.  Types are specified for all parameters and the return value.  The description of the dictionary returned is detailed, listing all keys and their types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking for the `user_id`, `file_id`, and `content` parameters.  While Pydantic could be used to achieve the same validation, the existing manual checks are sufficient and correctly handle the expected input types.  Using Pydantic here would add unnecessary complexity without significant benefit."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation of its three functional input parameters: `user_id`, `file_id`, and `content`.  Each parameter undergoes type checking using `isinstance` to ensure it's a string, string, and bytes, respectively.  Furthermore, value validation is performed: it checks if the `user_id` exists in the `DB['users']` and if the `file_id` exists within the user's files.  Appropriate `ValueError` exceptions with informative messages are raised for any validation failures.  All functional input parameters are validated before being used in subsequent operations."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`user_id`, `file_id`, `content`) are properly type-annotated with their expected types (str, str, bytes). The function's return type is clearly specified as `Dict[str, Any]`.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional.  It correctly handles the creation of a new revision, including generating a unique ID, encoding the content, creating the revision structure, and adding it to the file's revisions list.  Input validation for `user_id`, `file_id`, and `content` is correctly implemented, and the documented exceptions are raised appropriately. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `create_revision` does not handle any phone number or email address inputs.  Its inputs are `user_id`, `file_id`, and `content` (bytes), which are treated as strings and bytes respectively, without any attempt at phone number normalization or email validation.  Therefore, the criteria for phone number normalization and email validation are not applicable."
          }
        },
        "update_content": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the main steps: checksum calculation, base64 encoding (with handling for other encodings), content structure creation, revision creation, content update, and cache clearing.  The Args and Returns sections are well-structured and informative, correctly specifying types.  The description of the return dictionary is comprehensive, listing all keys with types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking for the three functional input parameters (`user_id`, `file_id`, `new_content`).  While Pydantic models could be used to achieve the same validation, the current manual checks are sufficient and correctly handle the expected types.  Using Pydantic here would add unnecessary complexity without providing significant additional benefits."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on all three functional input parameters (`user_id`, `file_id`, `new_content`).  It checks that `user_id` and `file_id` are strings and `new_content` is bytes.  It also performs value validation by checking if the `user_id` exists in the DB and if the `file_id` exists for the given `user_id`.  Error handling is present using `ValueError` exceptions with informative messages.  However, there's no explicit check for empty strings in `user_id` and `file_id`, which would be a beneficial addition.  While the code checks for the existence of the user and file, it doesn't validate the format or content of `file_id` beyond being a string.  Therefore, the validation is good but not comprehensive due to the lack of empty string checks and more robust `file_id` validation."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (user_id: str, file_id: str, new_content: bytes) are properly type-annotated with their expected types.  The function's return type is clearly specified as Dict[str, Any].  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and implements the core functionality of updating file content.  All functional input parameters (`user_id`, `file_id`, `new_content`) are used.  Exception handling for invalid input types and non-existent users/files is implemented. There are no placeholders or TODO comments. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `update_content` does not handle any phone numbers or email addresses as input.  Its inputs are a user ID, a file ID, and file content (as bytes). Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses on file content management and update processes, not user contact information."
          }
        },
        "export_content": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's main steps: checking for cached content, decoding, validation, export, caching, and return. The Args, Returns, and Raises sections are present and mostly accurate.  Types are specified for all parameters and the return value.  The documentation of the dictionary returned is quite detailed, listing all keys and their types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking (`isinstance`) to validate that `user_id`, `file_id`, and `target_mime` are strings.  While Pydantic models could be used, the current validation is sufficient and arguably simpler for this specific case.  The validation is complete for all functional input parameters.  Using Pydantic here would add unnecessary complexity."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on all three functional input parameters (`user_id`, `file_id`, `target_mime`), ensuring they are strings.  It also checks if the `user_id` and `file_id` represent existing users and files within the `DB`, respectively. This constitutes value validation for these parameters.  However, there's no validation on the `target_mime` beyond ensuring it's a string; it doesn't check if it's a valid MIME type.  The function also doesn't explicitly check for empty strings, although the database lookup implicitly handles this as an empty string would not represent a valid user or file ID.  Therefore, while most inputs are validated, the lack of MIME type validation and explicit empty string checks prevents a \"Comprehensive\" rating."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (user_id, file_id, target_mime) are properly type-annotated as strings.  The return type is clearly specified as `Dict[str, Any]`. The function does not use **kwargs."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional.  It correctly handles caching, decoding, and exporting file content.  All functional input parameters (`user_id`, `file_id`, `target_mime`) are used.  The documented exceptions are implemented. There are no placeholders or TODO comments. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `export_content` does not handle any phone number or email address inputs.  Its inputs are `user_id`, `file_id`, and `target_mime`, which are all treated as strings without any specific normalization or validation related to phone numbers or email addresses.  Therefore, the criteria for phone number normalization and email validation are not applicable to this function."
          }
        },
        "list_revisions": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's inputs (user_id and file_id) and their types. The Returns section correctly specifies the type as `List[Dict[str, Any]]` and details the structure of the dictionaries within the list, including the keys, types, and descriptions.  The Raises section correctly identifies the `ValueError` exceptions.  The type hinting is complete for parameters and return values."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses `isinstance` checks to validate that `user_id` and `file_id` are strings.  While Pydantic could be used, the existing validation is sufficient and arguably simpler for this specific case where only string type is required.  Pydantic would add overhead without providing significant additional benefits given the straightforward nature of the required validation.  The function does not use Pydantic models to validate the `user_id` and `file_id` inputs."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on both `user_id` and `file_id`, ensuring they are strings.  It also performs value validation by checking if the `user_id` exists in the `DB['users']` and if the `file_id` exists within the user's files.  This is a good level of validation. However, it lacks checks for empty strings in `user_id` and `file_id`. While the type check prevents non-string inputs, empty strings could still lead to errors downstream.  Therefore, it's not quite comprehensive.  Adding checks for empty strings would improve the validation."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`user_id` and `file_id`) are properly type-annotated as strings. The return type is clearly specified as `List[Dict[str, Any]]`.  The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly retrieves revisions based on user_id and file_id.  Input validation for `user_id` and `file_id` being strings is present and correctly raises `ValueError` if they are not strings.  The function also correctly raises a `ValueError` if the user or file is not found in the DB. The docstring accurately reflects the function's behavior and return type.  However, the lines `for file in files.values(): models.FileWithContentModel(**file)` and `models.FileWithContentModel(**file_data)` and `for revision in revisions: models.RevisionModel(**revision)` appear to be unnecessary.  These lines instantiate `models.FileWithContentModel` and `models.RevisionModel` but their results are not used. While this doesn't break functionality (given the context of using a mock DB), it's redundant and could be removed for improved efficiency.  The function is mostly complete and functional but could be improved by removing the unnecessary model instantiations."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list_revisions` does not handle any phone number or email address inputs.  Its inputs are `user_id` and `file_id`, which are treated as strings and validated only for their string type.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses solely on retrieving and validating file revision data from a database (represented by `DB`)."
          }
        }
      }
    },
    "gdrive/Drives.py": {
      "functions": {
        "create": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  It accurately describes the function's idempotent behavior using `requestId`. The Args section correctly documents all parameters, including default values and nested dictionary structures within the `body` parameter.  The Returns section adequately details the structure of the dictionary returned, listing all keys and their types. The Raises section correctly mentions `TypeError` and `ValidationError`.  Types are specified for all parameters and return values."
          },
          "pydantic_usage": {
            "status": "Partially Used",
            "notes": "The function uses Pydantic for validation of the `body` parameter, which is good. However, it performs basic type checking for `requestId` separately.  While this covers the basic validation needs, a Pydantic model could consolidate and potentially enhance this validation. A Pydantic model for `requestId` could enforce string length constraints or specific patterns if needed, making the validation more comprehensive and maintainable.  Currently, only `body` leverages Pydantic's capabilities;  `requestId` validation is handled manually.  Using a Pydantic model for both would improve consistency and potentially add more robust validation rules."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on both `requestId` (checking if it's a string) and `body` (checking if it's a dictionary).  It also implicitly handles `requestId` being None or an empty string by using the `if requestId:` condition.  The `body` parameter leverages Pydantic for more comprehensive validation, which likely handles value checks and constraints defined within the `CreateDriveBodyInputModel`. However, there's no explicit validation for the structure or content of the `restrictions` dictionary within the `body` parameter beyond the type check.  While Pydantic likely covers this, it's not explicitly shown in the provided code snippet.  Therefore, the validation is good but not entirely comprehensive due to this potential gap."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`requestId` and `body`) are properly type-annotated with their expected types (Optional[str] and Optional[Dict[str, Any]], respectively).  The function's return type is clearly specified as `Dict[str, Any]`.  The function does not use `**kwargs` parameters.  Complex types like `Optional` and `Dict` are correctly specified."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional.  It correctly handles idempotency checks using `requestId`, generates internal IDs when `requestId` is absent, and uses the `body` dictionary to populate the new drive's properties.  Exception handling for `TypeError` is implemented correctly. The docstring accurately reflects the function's behavior and return type. However,  the `body` parameter's `restrictions` sub-dictionary is not fully validated. While a Pydantic model is mentioned (`CreateDriveBodyInputModel`), the actual validation is missing.  The code only attempts to instantiate the model, but doesn't handle potential `ValidationError` exceptions appropriately beyond re-raising them.  A more robust solution would involve logging the error or providing more informative error messages.  Additionally, the function relies on helper functions `_ensure_user` and `_next_counter`, which are not defined in the provided code snippet, making a full assessment of completeness impossible without their implementation."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code does not handle phone numbers or email addresses.  It focuses on creating and managing shared drives, using a request ID and a body containing drive properties.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The code does include input validation for the structure of the `requestId` and `body` parameters, but this is unrelated to phone number or email processing."
          }
        },
        "delete": {
          "docstring_quality": {
            "status": "Excellent",
            "notes": "The docstring is well-written and accurately reflects the function's behavior.  It clearly explains the function's purpose,  the required `driveId` parameter, and the potential exceptions (`TypeError` and `NotFoundError`). The description of the function's effect on the system (permanently deleting a drive) is explicit and includes a warning about data loss.  The `Args`, `Returns`, and `Raises` sections are complete and correctly formatted.  The docstring correctly states that the function returns `None`.  Type hints are used consistently and accurately. There are no inconsistencies between the docstring and the implementation."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `driveId` parameter. It checks if `driveId` is a non-empty string and if a drive with that ID exists in the `DB`.  While Pydantic could be used, the existing validation is sufficient and clear.  Using Pydantic would add complexity without significant benefit in this simple case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `delete` has only one functional input parameter: `driveId`.  The validation for `driveId` is comprehensive. It checks for the correct data type (string) using `isinstance`, checks for emptiness using `.strip()`, and then performs a domain-specific check to ensure the `driveId` exists in the user's drives within the `DB`.  Appropriate `TypeError` and `NotFoundError` exceptions are raised with informative messages for invalid inputs.  All aspects of input validation are covered for the single functional parameter."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function has excellent parameter design.  All parameters (`driveId`) are properly type-annotated with their expected types (str). The return type is clearly specified as `None`.  No `**kwargs` parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the deletion of a shared drive based on the provided `driveId`.  It performs input validation to ensure `driveId` is a non-empty string and checks if the drive exists in the `DB` before attempting deletion.  The `NotFoundError` and `TypeError` exceptions are correctly raised in the appropriate scenarios. The function uses the `driveId` parameter effectively. The docstring accurately reflects the function's behavior, including the return type and exceptions raised.  There are no placeholders or incomplete logic."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `delete` does not handle phone numbers or email addresses.  Its input is a `driveId` (string), which is validated to ensure it's a non-empty string and exists in a database.  There is no phone number or email address normalization or validation performed.  Therefore, the categories related to phone number and email handling are not applicable."
          }
        },
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments and the structure of the returned dictionary, including nested structures within the `restrictions` dictionary.  The `Returns` section correctly mentions the possibility of returning `None`. The `Raises` section accurately reflects the exception handling in the code.  Types are specified for all parameters and return values using type hints."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses basic type checking and manual validation to ensure `driveId` is a non-empty string.  While Pydantic could be used, the current validation is sufficient and straightforward for this simple input.  Using Pydantic would add unnecessary complexity for this specific case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get` has only one functional input parameter: `driveId`.  The validation for `driveId` is comprehensive. It checks that `driveId` is a string using `isinstance` and that it's not an empty string using `.strip()`.  Appropriate `TypeError` exceptions with clear messages are raised for invalid inputs.  All aspects of type and value validation are present for the single functional input parameter."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get` has excellent parameter design and type annotations.  The single parameter `driveId` is correctly type-annotated as `str`. The return type `Optional[Dict[str, Any]]` is also clearly specified.  No `**kwargs` are used.  Complex types within the return type annotation are properly defined."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly implements input validation for `driveId` as documented, raising a TypeError for invalid input. It uses the provided `driveId` to attempt to retrieve data from the global `DB`. The return type and structure generally match the docstring, returning `None` if the drive is not found.  However, the function uses a hardcoded `userId = 'me'`, which limits its functionality and doesn't allow fetching drives for other users.  The docstring suggests the function should retrieve metadata for a given `driveId`, but the implementation is restricted to a single user.  This makes the function less complete than it could be."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle any phone numbers or email addresses.  Its input is a `driveId` (string), which is validated only for its type and non-emptiness.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses solely on retrieving data from a database based on a drive ID."
          }
        },
        "hide": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  The description of what the function does is clear.  The `Args` and `Returns` sections are well-structured, and types are specified for all parameters and the return value. The `Raises` section correctly identifies the `ValueError`.  The documentation of the dictionary returned is thorough, listing all key-value pairs with their types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `driveId` parameter. It checks if `driveId` is a string and if it's not empty or whitespace.  While Pydantic could be used, the existing validation is sufficient and correctly handles the single functional input parameter.  Using Pydantic would add unnecessary complexity for this simple validation task."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `hide` has only one functional input parameter: `driveId`.  The validation for `driveId` is comprehensive. It checks that `driveId` is a string (`isinstance`), that it's not empty or contains only whitespace (`not driveId or not driveId.strip()`), and raises a `ValueError` with a clear message if any of these checks fail.  All possible issues with the `driveId` parameter as a string are addressed before it's used."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function has excellent parameter design.  The `driveId` parameter is properly type-annotated as `str`. The return type is clearly specified as `Optional[Dict[str, Any]]`.  The function does not use `**kwargs`.  All type annotations are complete and accurately reflect the expected types."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly implements the hiding of a shared drive by setting the 'hidden' flag to True in the DB.  Input validation for `driveId` is performed as documented, and the documented `ValueError` is raised appropriately. The function correctly returns `None` if the drive is not found.  The docstring accurately reflects the return type and the structure of the returned dictionary when successful. However, the function lacks error handling for potential exceptions during database access (e.g., `KeyError` if `DB['users'][userId]` or `DB['users'][userId]['drives']` doesn't exist).  While unlikely given the context of a mock database, robust code would include such handling.  Adding a `try...except` block to gracefully handle potential `KeyError` exceptions would improve the function's completeness."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `hide` does not handle phone numbers or email addresses.  Its input is a `driveId` (string), which is validated for being a non-empty string.  No phone number or email address normalization or validation is performed or needed.  Therefore, the categories related to phone number and email handling are not applicable."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage.  It accurately describes the function's role in listing shared drives, including the use of filtering (`q`) and pagination (`pageSize`, `pageToken`). Default values for parameters are correctly stated.  The `Args` and `Returns` sections are well-structured, and types are specified.  The documentation of the nested dictionary structures within the `Returns` section is particularly thorough, although it could be slightly improved by using a more concise format (e.g., using a table for better readability). The `Raises` section correctly lists potential exceptions."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function performs manual input validation using `isinstance` checks and explicit comparisons for `pageSize` and type checks for `q` and `pageToken`.  While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing approach is sufficient and covers all functional input parameters.  The manual checks are clear and easy to understand in this context."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on its functional input parameters."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`pageSize`, `q`, `pageToken`) are properly type-annotated with their expected types (int, str, str). The function's return type is clearly specified as `Dict[str, Any]`.  No **kwargs parameters are used.  Complex types within the return dictionary are also properly specified (List[Dict[str, Any]])."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the listing of shared drives from the global `DB`, applying filtering based on the `q` parameter and pagination using `pageSize` and `pageToken`. All functional input parameters (`pageSize`, `q`, `pageToken`) are used appropriately.  The documented exceptions (`TypeError`, `ValueError`, `InvalidQueryError`) are all handled. There are no placeholders or TODO comments. The function's logic is complete and functional, and the docstring accurately reflects the function's behavior and return type.  The `userId` variable is used internally and is not a functional parameter."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle phone numbers or email addresses as input.  Its inputs are `pageSize` (integer), `q` (a query string for filtering drives), and `pageToken` (a base64 encoded pagination token).  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses on retrieving and paginating a list of shared drives based on a provided query."
          }
        },
        "unhide": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments and the expected return value, including the nested structure of the dictionary. The `Raises` section correctly identifies the `TypeError` exception.  Types are specified for all parameters and the return value using type hints.  The documentation of the dictionary structure in the return value is thorough."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation with `isinstance` and string length checks for the `driveId` parameter.  While Pydantic could provide a more structured and potentially more comprehensive approach (e.g., handling different error types more gracefully), the existing validation is sufficient for this simple case.  Using Pydantic would add unnecessary complexity for this specific function."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `unhide` has only one functional input parameter: `driveId`.  The validation for `driveId` is comprehensive. It checks that `driveId` is a string using `isinstance` and that it's not an empty string using `.strip()`.  Appropriate `TypeError` exceptions with clear messages are raised for invalid inputs.  All aspects of type and value validation relevant to this parameter are present."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `unhide` has excellent parameter design.  The single parameter `driveId` is correctly type-annotated as `str`. The return type `Optional[Dict[str, Any]]` is also clearly specified.  No `**kwargs` are used.  The type annotations are complete and accurately reflect the expected types."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly uses the `driveId` parameter for retrieving and modifying the drive in the global `DB`.  It correctly handles the case where the drive is not found by returning `None`. The exception handling for `TypeError` is also correctly implemented.  However, the function's logic is simplistic. It assumes a user ID of 'me' which might not always be the case in a real-world scenario.  A more robust implementation would likely require a mechanism to determine the appropriate user ID based on the context or additional input parameters.  Additionally, while the function correctly updates the `hidden` flag to `False`, it doesn't explicitly handle potential errors during the update process within the DB.  The docstring accurately reflects the function's behavior, except for the implicit assumption of 'me' as the userId."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `unhide` does not handle any phone numbers or email addresses.  Its input is a `driveId` (string), which is validated only for its type and non-empty nature. There is no phone number or email address normalization or validation performed.  Therefore, the categories of \"Excellent,\" \"Good,\" or \"Poor\" are not applicable."
          }
        },
        "update": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and mostly accurate. It clearly explains the function's purpose, arguments, return value, and exceptions.  The descriptions are helpful and the types are correctly specified.  The documentation of the nested `body` and return dictionaries is thorough, including nested structures and optional fields. The default value for the `body` parameter is correctly mentioned."
          },
          "pydantic_usage": {
            "status": "Properly Used",
            "notes": "The function uses a Pydantic model (`DriveUpdateBodyModel`) to validate the `body` parameter, which is a dictionary.  The `driveId` parameter is also validated using standard type checking to ensure it's a non-empty string.  This covers all functional input parameters.  The use of `model_dump(exclude_unset=True)` is a good practice for handling partial updates.  No further input validation is needed."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function demonstrates comprehensive input validation for both `driveId` and `body`."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`driveId` and `body`) are properly type-annotated with their expected types.  The `driveId` parameter is annotated as `str`, and the `body` parameter is annotated as `Optional[Dict[str, Any]]`. The return type is clearly specified as `Dict[str, Any]`.  The function does not use `**kwargs` parameters.  Complex types like `Optional` and `Dict` are properly specified."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the update functionality as described in its docstring.  All functional input parameters (`driveId` and `body`) are used appropriately.  The function includes comprehensive input validation, handling `TypeError` for incorrect input types and `ValidationError` for inconsistencies in the `body` dictionary using Pydantic.  The `NotFoundError` is also correctly raised if the specified `driveId` is not found in the DB. The logic correctly updates the existing drive data in the global `DB` with the validated data from `body`, and the updated data is returned.  The return value matches the docstring's description. There are no placeholders, TODOs, or pass statements.  The implementation is complete and functional within the context of the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `update` function does not handle any phone number or email address inputs.  Its purpose is to update metadata for a shared drive, using a `driveId` and a body containing drive properties.  There are no fields within the `body` dictionary that would accept or require phone number or email address data. Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        }
      }
    },
    "gdrive/Comments.py": {
      "functions": {
        "create": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'create': def create(fileId: str,\n          body: Optional[Dict[str, Any]] = None,\n          ) -> Dict[str, Any]:\n    \"\"\"Creates a body on a file.\n    \n    This function creates a new body on the specified Google Drive file with\n    input validation and error handling.\n    \n    Args:\n        fileId (str): The ID of the file to comment on.\n        body (Optional[Dict[str, Any]]): Dictionary containing comment properties. If None,\n            an empty dictionary is used. Supported keys:\n            - 'content' (str, required): The plain text content of the comment.\n            - 'author' (Optional[Dict[str, Any]]): Author information with keys:\n                - 'displayName' (str): Display name of the author.\n                - 'emailAddress' (str): Valid email address of the author.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted content with keys:\n                - 'value' (str): The quoted content text (required if quotedFileContent provided).\n                - 'mimeType' (str): MIME type of the quoted content (required if quotedFileContent provided).\n            - 'anchor' (Optional[str]): Anchor point for the comment.\n            - 'resolved' (Optional[bool]): Whether the comment is resolved (defaults to False).\n    \n    Returns:\n        Dict[str, Any]: Dictionary containing the created comment with the following keys:\n            - 'kind' (str): Resource type identifier ('drive#comment').\n            - 'id' (str): Unique comment identifier.\n            - 'fileId' (str): The ID of the file this comment belongs to.\n            - 'content' (str): The plain text content of the comment.\n            - 'htmlContent' (str): HTML-formatted content (same as content for plain text).\n            - 'author' (Dict[str, Any]): Author information dictionary containing:\n                {'kind': 'drive#user', 'displayName': str, 'emailAddress': str, 'me': bool, 'permissionId': str}\n            - 'createdTime' (str): RFC 3339 timestamp when the comment was created.\n            - 'modifiedTime' (str): RFC 3339 timestamp when the comment was last modified.\n            - 'resolved' (bool): Whether the comment has been resolved.\n            - 'deleted' (bool): Whether the comment has been deleted (always False for new comments).\n            - 'replies' (List): Empty list of replies for new comments.\n            - 'quotedFileContent' (Optional[Dict[str, Any]]): Quoted file content dictionary containing:\n                {'value': str, 'mimeType': str} (only present if quoted content provided).\n            - 'anchor' (Optional[str]): JSON string anchor point (only present if anchor provided).\n    \n    Raises:\n        ValidationError: If any input parameter fails validation.\n        FileNotFoundError: If the specified file does not exist.\n        PermissionDeniedError: If the user lacks permission to comment on the file.\n    \"\"\"\n    # Input validation using Pydantic model\n    if body is None:\n        body = {}\n    \n    # Prepare input data for validation\n    validation_data = {\n        'fileId': fileId,\n        'content': body.get('content', ''),\n        **body  # Include all other body fields\n    }\n    \n    # Validate input using Pydantic model\n    try:\n        validated_input = CommentCreateInput(**validation_data)\n    except PydanticValidationError as e:\n        # Convert Pydantic validation errors to custom ValidationError\n        error_messages = []\n        for error in e.errors():\n            field_name = '.'.join(str(loc) for loc in error['loc'])\n            error_messages.append(f\"{field_name}: {error['msg']}\")\n        raise ValidationError(f\"Validation failed: {'; '.join(error_messages)}\")\n    \n    # Ensure user exists\n    userId = 'me'\n    _ensure_user(userId)\n    \n    # Check if file exists - raise error if not found\n    if fileId not in DB['users'][userId]['files']:\n        raise FileNotFoundError(f\"File not found: {fileId}\")\n    \n    # Get file data for permission checking\n    file_data = DB['users'][userId]['files'][fileId]\n    \n    # Get user email for permission checking\n    user_email = DB['users'][userId]['about']['user'].get('emailAddress', '')\n    \n    # Check if user has permission to comment on this file\n    can_comment = False\n    \n    # Check if user is in the owners list\n    file_owners = file_data.get('owners', [])\n    if user_email in file_owners:\n        can_comment = True\n    \n    # Check permissions array for user's role\n    if not can_comment:\n        file_permissions = file_data.get('permissions', [])\n        for permission in file_permissions:\n            if permission.get('emailAddress') == user_email:\n                user_role = permission.get('role', '')\n                # Google Drive roles that allow commenting: commenter, editor, owner\n                if user_role in ['commenter', 'editor', 'owner']:\n                    can_comment = True\n                    break\n    \n    # Enforce permission check - only allow commenting if user has proper permissions\n    if not can_comment:\n        raise PermissionDeniedError(\"User does not have permission to create comments on this file\")\n    \n    # Generate unique comment ID\n    comment_id_num = _next_counter('comment')\n    comment_id = f\"comment_{comment_id_num}\"\n    \n    # Get current timestamp in RFC 3339 format\n    current_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n    \n    # Prepare author information - use provided author or default user info  \n    author_info = {\n        'kind': 'drive#user',\n        'displayName': validated_input.author.displayName if validated_input.author else DB['users'][userId]['about']['user']['displayName'],\n        'emailAddress': str(validated_input.author.emailAddress) if validated_input.author else DB['users'][userId]['about']['user']['emailAddress'],\n        'me': True,\n        'permissionId': 'me'\n    }\n    \n    # Create the comment object\n    new_comment = {\n        'kind': 'drive#comment',\n        'id': comment_id,\n        'fileId': validated_input.fileId,\n        'content': validated_input.content,\n        'htmlContent': validated_input.content,\n        'author': author_info,\n        'createdTime': current_time,\n        'modifiedTime': current_time,\n        'resolved': validated_input.resolved or False,\n        'deleted': False,\n        'replies': []  # Empty replies list for new comments\n    }\n    \n    # Add optional fields if provided\n    if validated_input.quotedFileContent:\n        new_comment['quotedFileContent'] = {\n            'value': validated_input.quotedFileContent.value,\n            'mimeType': validated_input.quotedFileContent.mimeType\n        }\n    \n    if validated_input.anchor:\n        new_comment['anchor'] = validated_input.anchor\n    \n    # Store the comment in the database\n    if 'comments' not in DB['users'][userId]:\n        DB['users'][userId]['comments'] = {}\n    \n    DB['users'][userId]['comments'][comment_id] = new_comment\n    \n    return new_comment\n\n"
          }
        },
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a decent overview of the function's purpose.  It accurately describes the function's arguments and their types. The default value for `includeDeleted` is correctly documented.  The `Returns` section correctly specifies the return type and lists the keys of the dictionary.  The types of the dictionary keys are also specified, which is good."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function does not use Pydantic models for input validation.  While the function parameters `fileId` and `commentId` are type hinted as strings, there's no validation to ensure they are in the correct format or exist within the `DB`.  The `includeDeleted` parameter has type hinting but no validation.  Adding Pydantic models would significantly improve the robustness of the input validation by enforcing data types and potentially adding constraints like string length or format requirements for IDs.  Currently, there is no input validation beyond type hinting."
          },
          "input_validation": {
            "status": "Partial",
            "notes": "The function performs type validation implicitly through type hints (`fileId: str`, `commentId: str`, `includeDeleted: bool`). However, it lacks explicit value validation for `fileId` and `commentId`.  It does not check for empty strings or None values for these parameters, nor does it check if the `commentId` exists within the `DB['users'][userId]['comments']` dictionary before attempting to access it.  The `includeDeleted` parameter is a boolean and doesn't require further validation beyond its type.  Therefore, while type validation is present, crucial value and null/empty checks are missing for the key functional parameters."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `commentId`, `includeDeleted`) are properly type-annotated with their expected types (str, str, bool respectively).  The return type `Optional[Dict[str, Any]]` is also clearly specified. The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly retrieves a comment from the global `DB` based on `fileId` and `commentId`.  The `includeDeleted` parameter is not used in the function's logic, which is a minor gap.  The function correctly returns a dictionary matching the docstring's description if a matching comment is found, and `None` otherwise.  The docstring accurately reflects the function's behavior."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle any phone number or email address inputs.  Its parameters and purpose are related to retrieving comments from a database based on file and comment IDs. Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-structured and mostly accurate. It clearly explains the function's purpose, parameters, return value, and exceptions.  Default values are correctly specified and explained. The `Args` and `Returns` sections are comprehensive, including descriptions of nested dictionary structures within the return value.  Type hints are present and mostly consistent."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for all functional parameters (`fileId`, `includeDeleted`, `pageSize`, `pageToken`, `startModifiedTime`).  It performs type checking and range/format validation as needed. While Pydantic could provide a more structured and potentially more concise way to achieve the same validation, the existing manual approach is comprehensive and effective for this specific function.  Therefore, Pydantic is not strictly needed."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "All functional input parameters (`fileId`, `includeDeleted`, `pageSize`, `pageToken`, `startModifiedTime`) undergo thorough validation.  `fileId` is checked for string type and non-emptiness. `includeDeleted` is checked for boolean type. `pageSize` is checked for integer type and range (1-100). `pageToken` is checked for string type and, if not empty, for integer string format. `startModifiedTime`, if provided, is checked for string type and RFC 3339 timestamp format using `datetime.fromisoformat`.  Appropriate exceptions (`TypeError`, `ValueError`, `PageSizeOutOfBoundsError`, `MalformedPageTokenError`, `InvalidTimestampFormatError`) are raised with informative error messages for invalid inputs.  All validation checks occur before the parameters are used in the function's logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, includeDeleted, pageSize, pageToken, startModifiedTime) are properly type-annotated with their expected types using type hints (str, Optional[bool], Optional[int], Optional[str], Optional[str]). The function's return type is clearly specified as Dict[str, Any].  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the listing of comments based on the provided parameters.  All functional input parameters (`fileId`, `includeDeleted`, `pageSize`, `pageToken`, `startModifiedTime`) are used appropriately in the filtering and pagination logic.  All documented exceptions are handled. There are no TODOs, pass statements, or placeholder implementations. The function's logic is complete and functional given the global `DB` dictionary. The docstring accurately reflects the function's behavior, including return types and exception handling."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle any phone number or email address inputs.  Its purpose is to list comments for a file given a file ID and other parameters related to filtering and pagination.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "update": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments and their types, including the nested structures within the `body` dictionary. The `Returns` section correctly details the structure of the returned dictionary.  Default values are mentioned for the `body` parameter.  Types are specified for all parameters and the return value.  The documentation of the dictionaries is thorough, covering keys, types, and nested structures."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function lacks any input validation using Pydantic models or other methods for its functional parameters (`fileId`, `commentId`, `body`).  While `fileId` and `commentId` are declared as strings, there's no check to ensure they are non-empty or conform to any specific format. The `body` parameter, although optionally a dictionary, isn't validated against the expected structure or types of its nested keys ('content', 'author', etc.).  Using Pydantic models would significantly improve the robustness of this function by enforcing data types and structure, preventing unexpected errors and improving code clarity."
          },
          "input_validation": {
            "status": "Partial",
            "notes": "The function performs some input validation but is not comprehensive."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `commentId`, `body`) have proper type annotations.  The return type is also clearly specified as `Optional[Dict[str, Any]]`.  The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly updates a comment in the global `DB` if it exists and belongs to the specified file.  The `body` parameter is used correctly to update the comment. The updated comment, including a new `modifiedTime`, is returned as specified in the docstring. However, there's a lack of error handling.  If `DB['users'][userId]['comments']` doesn't exist, a `KeyError` will be raised.  While the function correctly handles the case where the comment doesn't exist or belongs to a different file by returning `None`, more robust error handling for potential `KeyError` exceptions would improve the function's robustness."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `update` does not handle phone numbers or email addresses as input.  The `body` dictionary can contain an email address within the `author` dictionary, but the function doesn't perform any validation or normalization on it.  There's no processing or checks for the format or validity of email addresses or phone numbers.  Therefore, the categories of \"Excellent,\" \"Good,\" or \"Poor\" are not applicable."
          }
        },
        "delete": {
          "docstring_quality": {
            "status": "Excellent",
            "notes": "The docstring is well-written and accurately reflects the function's behavior.  It clearly explains the function's purpose,  lists all arguments with their types and descriptions, correctly specifies the return type as `None`, and comprehensively documents all possible exceptions (`TypeError`, `ValueError`, `NotFoundError`). The descriptions are concise and easy to understand.  There are no inconsistencies between the docstring and the implementation; the docstring accurately reflects that the function raises the specified exceptions under the described conditions and returns `None`.  The docstring is complete enough for someone to use the function effectively."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `fileId` and `commentId` parameters.  It checks that they are strings and that they are not empty.  While Pydantic could provide a more concise and potentially more feature-rich way to perform this validation, the existing manual checks are sufficient and cover all aspects of the required input validation.  Using Pydantic would be an improvement in terms of code readability and maintainability, but it's not strictly necessary given the existing validation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation of both functional input parameters, `fileId` and `commentId`.  Both are checked for correct type (string) using `isinstance` and for non-empty values using `.strip()`.  Appropriate `TypeError` and `ValueError` exceptions are raised with informative messages for invalid inputs.  All functional input parameters are validated before being used in subsequent operations."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "Both function parameters (`fileId` and `commentId`) are properly type-annotated as strings.  The return type is annotated as `None`.  The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the deletion of a comment from the in-memory database (`DB`).  All functional input parameters (`fileId` and `commentId`) are used to identify and remove the comment.  All documented exceptions (`TypeError`, `ValueError`, `NotFoundError`) are properly raised under the specified conditions. The docstring accurately reflects the function's behavior, including the return type and raised exceptions. There are no placeholders or TODO comments. The logic is complete and functional within the constraints of using the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `delete` does not handle any phone numbers or email addresses.  Its inputs are `fileId` and `commentId`, which are treated as strings and validated for non-emptiness and correct type.  Therefore, the criteria of phone number normalization and email validation are not applicable."
          }
        }
      }
    },
    "gdrive/About.py": {
      "functions": {
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and generally accurate, providing a good overview of the function's purpose, arguments, return value, and exceptions.  It correctly describes the `fields` parameter's behavior, including the use of '*' and comma-separated values with dot notation for nested fields. The `Returns` section is comprehensive, detailing the structure of the dictionary response, including nested dictionaries and lists.  The `Raises` section accurately lists the potential exceptions.  Types are specified for all parameters and the return value using type hints.  The documentation of the dictionary structure is quite thorough."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses basic type checking (`isinstance`) and manual validation (`fields.strip()`) to ensure the `fields` parameter is a non-empty string.  While Pydantic could provide a more structured and potentially more comprehensive approach (e.g., handling unexpected characters or enforcing a specific format), the current validation is sufficient for the simple requirements of this function.  The existing validation adequately addresses potential errors related to the `fields` parameter.  Using Pydantic would add complexity without significant benefit in this specific case."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs good input validation on the `fields` parameter, the only functional input.  Type validation (`isinstance(fields, str)`) and value validation (`fields.strip()`) are both present, checking for empty or whitespace-only strings.  Error handling is also appropriate, raising `TypeError` and `ValueError` with informative messages.  However, there's no validation to ensure that the field names specified in `fields` actually exist within the `about_data` structure.  While the code handles nested fields and gracefully skips non-existent fields, it doesn't explicitly raise an error if a user requests a field that is not part of the API's response structure.  Adding such a check would make the validation more comprehensive."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get` has excellent parameter design.  The single parameter `fields` is properly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` are used.  Complex types within the return annotation are correctly specified using `Dict` and `List`."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely implements its intended functionality.  It correctly handles input validation, retrieves data from the global `DB`, filters the results based on the `fields` parameter, and manages nested fields.  The handling of `folderColorPalette` to ensure it's a list is a good addition. The exception handling for `KeyError` is also correctly implemented."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle phone numbers or email addresses as input.  Its purpose is to retrieve and filter data from a Google Drive API (simulated here with a `DB` variable).  Therefore, the criteria of phone number normalization and email validation are not applicable. The function focuses on input validation and filtering of a different type of data (fields from a Drive API response)."
          }
        }
      }
    },
    "gdrive/Permissions.py": {
      "functions": {
        "create": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  It accurately describes the function's arguments, including default values and possible types. The `Returns` section correctly details the structure of the returned dictionary. The `Raises` section lists the expected exceptions.  The documentation of the `body` dictionary is thorough, specifying key names, types, and possible values."
          },
          "pydantic_usage": {
            "status": "Properly Used",
            "notes": "The function uses a Pydantic model (`PermissionBodyModel`) to validate the `body` parameter.  The `fileId` parameter is also validated using type checking and a check for empty strings.  While a Pydantic model could be created to encompass both `fileId` and `body` for a more unified approach, the current implementation is sufficient and correctly uses Pydantic for validation of the `body` dictionary.  The validation is comprehensive for the functional parameters."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function demonstrates good input validation for the `fileId` parameter, checking for both type and emptiness.  The `body` parameter is validated using a Pydantic model (implied by `PermissionBodyModel(**body)`), which presumably handles type and value validation comprehensively for its constituent fields ('role', 'type', 'emailAddress', 'domain', 'allowFileDiscovery', 'expirationTime').  However, the code doesn't explicitly show the definition of `PermissionBodyModel`, so we must assume it performs thorough validation.  If `PermissionBodyModel` lacks validation for any of its fields, the overall validation would be downgraded.  The absence of explicit validation for the existence of the `fileId` in the `DB` before the `try-except` block is a minor gap, although the `ResourceNotFoundError` exception suggests this check is performed implicitly within the `_ensure_user` and subsequent file lookup.  If `_ensure_user` or the file lookup does not perform this check, the validation would be considered partial."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId` and `body`) are properly type-annotated with their expected types.  The `fileId` parameter is annotated as a string (`str`), and the `body` parameter is annotated as an optional dictionary (`Optional[Dict[str, Any]]`). The function's return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` parameter is used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional. It correctly handles the `fileId` parameter, validating its type and emptiness.  Exception handling for `TypeError`, `ValueError`, and `ResourceNotFoundError` is implemented. The use of Pydantic (implied by `PermissionBodyModel`) for validating the `body` parameter is a good approach, ensuring data integrity.  The logic for creating a new permission and saving it to the `DB` is implemented. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `create` does not handle phone numbers at all.  It handles email addresses by converting them to lowercase in the `_processed_body` section, which is a minimal form of normalization (not validation).  However, there's no validation to check for a valid email address format.  The function primarily focuses on creating file permissions and doesn't involve phone number processing or robust email validation beyond lowercasing.  Therefore, the \"Not Applicable\" category is the most accurate."
          }
        },
        "delete": {
          "docstring_quality": {
            "status": "Excellent",
            "notes": "The docstring is well-written and comprehensive.  It clearly explains the function's purpose, accurately describes the arguments and their types (including default values), specifies the return type, and exhaustively lists all possible exceptions with informative descriptions. The descriptions of the exceptions are particularly helpful, detailing the conditions under which each exception is raised and providing context-specific information (e.g., permission requirements for shared drives vs. My Drive).  The docstring accurately reflects the function's behavior and the types of all parameters and the return value. There are no inconsistencies between the docstring and the implementation.  The level of detail provided makes the function easily understandable and usable based solely on the docstring."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for all functional parameters (`fileId`, `permissionId`, `supportsAllDrives`, `supportsTeamDrives`, `useDomainAdminAccess`).  It checks the types and values of these parameters directly. While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing manual checks are comprehensive and cover all aspects of input validation required for the functional parameters.  Therefore, Pydantic is not strictly needed for this function."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on all its functional input parameters (`fileId` and `permissionId`).  Type validation (`isinstance`) ensures they are strings. Value validation checks that they are not empty or whitespace-only strings using `.strip()`.  The optional boolean parameters (`supportsAllDrives`, `supportsTeamDrives`, `useDomainAdminAccess`) are also validated to ensure they are booleans using `isinstance`.  Appropriate `TypeError` and `ValueError` exceptions are raised with clear error messages for invalid inputs.  All functional parameters are checked before being used in the core logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `permissionId`, `supportsAllDrives`, `supportsTeamDrives`, `useDomainAdminAccess`) are properly type-annotated with their expected types (str and Optional[bool]). The function's return type is clearly specified as `None`.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the deletion of a permission based on the provided `fileId` and `permissionId`.  All functional input parameters (`fileId`, `permissionId`, `supportsAllDrives`, `supportsTeamDrives`, `useDomainAdminAccess`) are used appropriately in the logic.  All documented exceptions are handled. There are no TODOs, pass statements, or placeholder implementations. The logic is complete and functional given the global `DB` dictionary. The docstring accurately reflects the function's behavior, including the return type and raised exceptions."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code does not handle any phone number or email address inputs.  The function deals exclusively with file and permission IDs within a seemingly custom file management system represented by the `DB` variable.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The code does, however, demonstrate good input validation for the parameters it *does* use (fileId, permissionId, and the boolean flags)."
          }
        },
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's main task: retrieving a permission by ID, considering different access scenarios (shared drives, domain admin access).  Default values for boolean parameters are correctly stated and explained. The `Args` and `Returns` sections are well-structured, listing parameters with types and descriptions.  The `Returns` section provides a comprehensive description of the dictionary structure, including key names and types. The `Raises` section correctly mentions `TypeError` and `ValueError`.  Types are specified for all parameters and the return value."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking and value validation for the `fileId`, `permissionId`, `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess` parameters.  While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing approach is functional and covers all the necessary checks for the functional input parameters.  Using Pydantic would add overhead without significant benefit in this specific case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on its functional input parameters.  `fileId` and `permissionId` are checked for correct type (string) and non-emptiness (using `.strip()` to handle whitespace).  `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess` are all correctly checked to ensure they are booleans.  Appropriate `TypeError` and `ValueError` exceptions are raised with informative messages for invalid inputs. All functional parameters are validated before being used in the function's logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, permissionId, supportsAllDrives, supportsTeamDrives, useDomainAdminAccess) are properly type-annotated with their expected types (str, str, bool, bool, bool respectively). The function's return type is clearly specified as Optional[Dict[str, Any]].  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the retrieval of a permission based on the provided fileId and permissionId.  All functional input parameters (`fileId`, `permissionId`, `supportsAllDrives`, `useDomainAdminAccess`) are used appropriately in the logic to determine the search scope.  The documented exceptions (`TypeError` and `ValueError`) are correctly raised for invalid input. There are no placeholders or TODO comments. The function's logic correctly searches the `DB` for the permission, considering different access scenarios (shared drives, domain admin access). The docstring accurately reflects the function's behavior and return type.  The `supportsTeamDrives` parameter is deprecated, as noted in the docstring, but its presence doesn't negatively impact the functionality; it's simply treated as an alternative to `supportsAllDrives`."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle any phone number or email address inputs.  Its parameters and return values deal exclusively with file and permission IDs, booleans indicating drive access, and a dictionary representing permission details.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments, including their types and default values. The `Returns` section correctly specifies the dictionary structure, including nested types like `List[PermissionResourceModel]`, although the definition of `PermissionResourceModel` is missing (it should be added for completeness).  The `Raises` section correctly lists the exceptions.  The description of how `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess` affect the returned permissions is clear."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses type checking (`isinstance`) to validate the `fileId`, `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess` parameters.  While Pydantic could be used, the existing type checking is sufficient for this simple validation task.  The current approach is clear, concise, and directly addresses the potential type errors.  Using Pydantic would add complexity without significant benefit in this case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive type validation on all four functional input parameters (`fileId`, `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess`).  Each parameter is checked using `isinstance` to ensure it matches the expected type (string for `fileId` and boolean for the other three).  No value validation beyond type checking is performed (e.g., no checks for empty strings in `fileId` or specific boolean values), but the type checking is thorough and covers all functional inputs.  Appropriate `TypeError` exceptions are raised for type mismatches.  While there's no explicit null check, the `isinstance` checks implicitly handle `None` values as they would fail the type check.  The function also performs a domain-specific constraint check by verifying the existence of `fileId` within the simulated database (`DB`).  This is a crucial check for the function's logic and prevents errors later in the execution."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, supportsAllDrives, supportsTeamDrives, useDomainAdminAccess) are properly type-annotated with their expected types (str, Optional[bool], Optional[bool], Optional[bool] respectively).  The function's return type is clearly specified as Dict[str, Any].  The function does not use **kwargs parameters.  Complex types like Optional and Dict are properly specified."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the listing of file permissions based on the provided `fileId`, `supportsAllDrives`, `supportsTeamDrives`, and `useDomainAdminAccess` parameters.  All functional input parameters are used.  The documented `TypeError` and `NotFoundError` exceptions are properly handled. There are no TODOs, pass statements, or placeholder implementations. The logic correctly retrieves permissions from the global `DB`, aggregating them based on the boolean flags. The docstring accurately reflects the function's behavior and return type.  The function uses a custom `PermissionListModel` which is assumed to be defined elsewhere and correctly handles the transformation of the data into the specified dictionary format."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle any phone number or email address inputs.  Its purpose is to list file permissions from a simulated database (`DB`).  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function does perform input validation for its own parameters (fileId and boolean flags), ensuring they are of the correct type, which is good practice. However, this is unrelated to the specified phone number and email address processing requirements."
          }
        },
        "update": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is mostly well-written and informative. It clearly explains the function's purpose, arguments, return value, and exceptions.  The descriptions of the `body` dictionary's keys and the return dictionary's keys are thorough and helpful. Default values for `body` and `transferOwnership` are correctly documented.  Types are specified for all parameters and the return value."
          },
          "pydantic_usage": {
            "status": "Properly Used",
            "notes": "The function uses a Pydantic model (`PermissionBodyUpdateModel`) to validate the `body` parameter.  The `fileId`, `permissionId`, and `transferOwnership` parameters are validated using `isinstance` checks.  This covers all functional input parameters. While `isinstance` checks are sufficient for these specific parameters, using Pydantic models for all inputs would offer a more consistent and potentially more expressive validation approach, especially if more complex validation rules were needed for `fileId` or `permissionId` in the future.  However, given the current simple validation requirements, the existing approach is acceptable."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on all its functional input parameters."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `permissionId`, `body`, `transferOwnership`) are properly type-annotated with their expected types.  The function's return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` parameter is used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the update functionality as described in its docstring. All functional input parameters (`fileId`, `permissionId`, `body`, `transferOwnership`) are used appropriately in the logic.  All documented exceptions are handled. There are no TODOs, pass statements, or placeholder implementations. The logic for both standard permission updates and ownership transfers is complete and functional, correctly interacting with the global `DB` dictionary. The return value matches the docstring's description."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code does not handle phone numbers or email addresses as inputs.  The `body` parameter can contain an `emailAddress` field, but this is only validated as a string; there's no specific normalization or validation beyond ensuring it's a string.  No phone number input is present. Therefore, the criteria of phone number normalization and email address validation are not applicable."
          }
        }
      }
    },
    "gdrive/Apps.py": {
      "functions": {
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments and the structure of the returned dictionary, including nested structures like the `icons` list.  The `Args`, `Returns`, and `Raises` sections are well-structured and informative. Types are consistently specified for parameters and return values using type hints."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `appId` parameter.  It checks if `appId` is a string and if it's not empty or whitespace.  While Pydantic could be used, the current manual validation is sufficient and correctly handles the required checks.  Using Pydantic wouldn't add significant value in this simple case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get` has only one functional input parameter, `appId`.  The validation for `appId` is comprehensive. It checks for the correct data type (string) using `isinstance`, and it checks for empty or whitespace-only strings using `not appId or not appId.strip()`. Appropriate `TypeError` and `ValueError` exceptions are raised with clear error messages in case of invalid input.  All possible issues with the `appId` parameter are addressed before it's used."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get` has excellent parameter design.  All parameters (`appId`) are properly type-annotated with their expected types (str). The return type `Optional[Dict[str, Any]]` is clearly specified, handling the potential absence of a matching app.  Complex types within the return type annotation (Dict, Optional, List) are also correctly specified. No `**kwargs` are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly retrieves an app from the global `DB` based on the provided `appId`.  Input validation ensures that `appId` is a string and not empty.  All documented exceptions (`TypeError`, `ValueError`) are handled. The function's logic is complete and directly reflects the docstring's description of its behavior and return type.  The return value accurately reflects the presence or absence of the app in the database. There are no placeholders or TODO comments."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle phone numbers or email addresses as input.  Its sole input is an `appId` (string), which is validated for type and emptiness.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses solely on retrieving app data from a database (presumably represented by `DB`)."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and mostly accurate. It clearly explains the function's purpose,  lists all parameters with their types and default values, and describes the return value with good detail, including nested dictionary structures.  The `Raises` section correctly identifies the `TypeError` and `ValueError` exceptions.  The type hinting is complete and accurate. The documentation accurately reflects the handling of the `languageCode` parameter as unused but included for API compatibility."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `appFilterExtensions` and `appFilterMimeTypes` parameters.  It checks that they are strings, and then performs additional validation on their content to ensure correct formatting.  The `languageCode` parameter is not used functionally and thus doesn't require validation.  While Pydantic could be used, the existing manual validation is sufficient and arguably more readable in this specific case.  The manual approach directly expresses the validation logic, making it easier to understand the constraints on the input.  Using Pydantic would add complexity without significant benefit in this context."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function demonstrates comprehensive input validation for its functional parameters (`appFilterExtensions` and `appFilterMimeTypes`).  Both parameters undergo type checking to ensure they are strings.  Furthermore, value validation is performed to check for:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`appFilterExtensions`, `appFilterMimeTypes`, `languageCode`) are properly type-annotated as strings.  The return type is clearly specified as `Dict[str, Any]`. The function does not use `**kwargs`."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the described functionality.  It validates inputs as documented, applies filtering based on `appFilterExtensions` and `appFilterMimeTypes`, and returns a dictionary matching the specified structure. All functional parameters (`appFilterExtensions`, `appFilterMimeTypes`) are used.  The `languageCode` parameter is correctly noted as unused in the docstring and implementation. There are no placeholders, TODOs, or pass statements. The exception handling is complete and accurate. The docstring accurately reflects the function's behavior and return type.  The logic is complete and functional given the use of the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle any phone numbers or email addresses.  Its purpose is to list installed applications based on filters for file extensions and MIME types.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function does a good job of validating its input parameters (appFilterExtensions and appFilterMimeTypes) for correct format, but this is unrelated to the specified criteria for phone number and email handling."
          }
        }
      }
    },
    "gdrive/Channels.py": {
      "functions": {
        "stop": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's behavior of stopping a resource channel. The Args section correctly lists all parameters with types and descriptions. The default value for the `resource` parameter (None) is mentioned.  The Raises section correctly identifies the `ValidationError` and `ChannelNotFoundError` exceptions.  The return type (`None`) is correctly specified.  The documentation of the `resource` dictionary is detailed, listing all required keys and their types."
          },
          "pydantic_usage": {
            "status": "Properly Used",
            "notes": "The function uses a Pydantic model (`ChannelResourceModel`) to validate the `resource` parameter, which is the only functional input requiring validation.  The `try...except` block correctly handles `PydanticValidationError`.  All the required keys of the `resource` dictionary are validated by the Pydantic model.  No other input validation is needed because the Pydantic model covers all aspects of the functional input."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `stop` performs comprehensive validation of its single functional input parameter, `resource`.  It leverages Pydantic's `ChannelResourceModel` for type and value validation, ensuring that all required keys ('id', 'resourceId', 'resourceUri', 'token', 'expiration', 'type', 'address', 'payload', 'params') are present and of the correct type.  The `try-except` block around the Pydantic validation provides robust error handling, raising a `ValidationError` with a descriptive message if validation fails.  Additionally, a null check is performed explicitly (`if resource is None: resource = {}`), and a check for the existence of the channel ID in the `DB` is performed before attempting to stop the channel, preventing errors related to non-existent channels.  All functional input aspects are validated."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `stop` has an excellent parameter design.  The single parameter `resource` is properly type-annotated as `Optional[Dict[str, Any]]`. The return type is clearly specified as `None`.  No `**kwargs` are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the `stop` functionality as described in its docstring.  It handles the `resource` parameter comprehensively, validating it using Pydantic and gracefully handling the case where it's `None` or empty.  The function correctly checks for the existence of the channel before attempting to remove it, raising the appropriate `ChannelNotFoundError` if necessary.  All documented exceptions are handled. There are no placeholders or TODO comments. The logic is complete and functional given the use of the global `DB` dictionary. The docstring accurately reflects the function's behavior and return type.  All functional input parameters (`resource`) are used."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `stop` function does not handle any phone number or email address inputs.  Its purpose is to stop watching resources via a channel, using a dictionary containing various channel properties (ID, resource ID, URI, token, etc.).  There is no processing or validation of phone numbers or email addresses within the function's logic.  Therefore, the criteria for phone number normalization and email validation are not applicable."
          }
        }
      }
    },
    "gdrive/Changes.py": {
      "functions": {
        "getStartPageToken": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and mostly accurate. It clearly explains the function's purpose,  the meaning of each parameter (including default values and deprecated parameters), and the structure of the returned dictionary.  The `Raises` section correctly lists the potential exceptions.  Types are specified for all parameters and the return value.  The documentation of the dictionary return value is also quite good."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking and validation for its functional input parameters (`driveId`, `supportsAllDrives`, `supportsTeamDrives`, `teamDriveId`).  While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing manual checks adequately cover the type and basic constraint validation needs.  The checks for deprecated parameters and their handling are also appropriately implemented.  Using Pydantic wouldn't add significant value in this specific case given the simplicity of the validation logic."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function performs type validation on all four functional input parameters (`driveId`, `supportsAllDrives`, `supportsTeamDrives`, `teamDriveId`).  It also includes checks for empty or whitespace-only `driveId` strings.  Additionally, it validates that if `driveId` is provided, `supportsAllDrives` must be True.  The handling of deprecated parameters (`supportsTeamDrives`, `teamDriveId`) includes warnings and attempts to maintain backward compatibility, but it doesn't strictly validate the deprecated parameters themselves beyond type checking.  While the validation is good, it could be improved by adding more robust checks on the `driveId` format (e.g., checking if it's a valid Google Drive ID using a regular expression or external API call).  The current validation is sufficient to prevent most common errors but lacks a comprehensive check for the format of the `driveId`."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (driveId, supportsAllDrives, supportsTeamDrives, teamDriveId) are properly type-annotated with their expected types (Optional[str] or Optional[bool]). The function's return type is clearly specified as Dict[str, Any].  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly implements the core logic of generating or retrieving a start page token using the global `DB`.  It handles deprecated parameters (`supportsTeamDrives`, `teamDriveId`) with warnings and backward compatibility logic. Input validation is performed for all functional parameters (`driveId`, `supportsAllDrives`).  The function correctly returns a dictionary matching the docstring's specification."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `getStartPageToken` does not handle any phone numbers or email addresses.  Its inputs are related to Google Drive IDs and boolean flags for drive access, none of which are phone numbers or email addresses. Therefore, the criteria of phone number normalization and email validation are not applicable."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's role in listing changes within a Google Drive environment, relevant for an MCP server needing to track file system changes.  All parameters are documented with types and descriptions, including default values. The `Returns` section correctly specifies the dictionary structure, although it could benefit from more precise descriptions of some nested dictionary keys (e.g.,  `file` dictionary contents could be elaborated). The `Raises` section correctly lists the exceptions.  Types are specified for all parameters and return values."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function performs manual input validation for all functional parameters using type checking and range checks where applicable.  While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing manual checks are comprehensive and cover all the necessary aspects.  The use of Pydantic would not significantly improve the validation in this specific case, given the relatively simple data types and validation rules."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function demonstrates comprehensive input validation for all its functional parameters.  Each parameter undergoes type checking using `isinstance()`.  `pageSize` is checked for a valid range (1-1000). `pageToken` is checked for emptiness and whitespace. The `spaces` parameter is validated against a list of allowed values.  `includePermissionsForView` is checked for the allowed value \"published\".  The function also correctly handles potential conflicts between `restrictToMyDrive`, `driveId`, and `teamDriveId`, raising `InvalidRequestError` when necessary.  Appropriate `ValidationError` and `InvalidRequestError` exceptions are raised with informative messages for invalid inputs.  The deprecated parameters are handled gracefully with warnings and their values are appropriately mapped to their current counterparts.  All functional parameters are validated before being used in any logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters are properly type-annotated with their expected types (str, bool, int). The function's return type is clearly specified as `Dict[str, Any]`.  The function does not use **kwargs parameters."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional, correctly handling input validation and deprecated parameters with warnings.  The core logic of retrieving and filtering changes from the simulated database (`DB`) works as intended.  Pagination and token generation are implemented.  All documented exceptions are handled.  The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle any phone number or email address inputs.  Its parameters and purpose are related to Google Drive API interactions (listing changes in a Google Drive account).  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "watch": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a fairly comprehensive description of the `watch` function's purpose and usage within an MCP server context.  It accurately reflects the function's simulation nature.  All parameters are documented with their types and descriptions, including default values. The `Args` section is well-structured and explains the purpose of each parameter effectively. The `Returns` section clearly specifies the return type and structure, including the keys and types within the dictionary. The `Raises` section correctly lists potential exceptions.  Type information is complete for parameters and return values.  The documentation of the `resource` dictionary is detailed, specifying expected keys, types, and nested structures."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function performs extensive manual input validation for all functional parameters.  It checks types, ranges (for `pageSize`), and constraints (e.g., `restrictToMyDrive` conflicts with `driveId`). While Pydantic could provide a more concise and potentially type-safer way to achieve the same validation, the existing manual approach is comprehensive and effective.  The use of Pydantic wouldn't fundamentally change the validation logic, only its structure."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function demonstrates comprehensive input validation for all its functional parameters.  Each parameter undergoes type checking using `isinstance`.  `pageToken` is checked for emptiness and whitespace. `pageSize` is validated against a specified range.  The `spaces` parameter is checked against a list of allowed values. The `driveId` parameter is checked for emptiness and its interaction with `supportsAllDrives` is validated.  `includePermissionsForView` is checked for a valid value.  The `resource` dictionary's required fields are validated.  Appropriate exceptions (`ValidationError` and `InvalidRequestError`) with informative messages are raised for invalid inputs.  Deprecated parameters are handled with warnings and their logic is integrated into the validation process.  The function also performs checks for conflicting parameter combinations.  All functional parameters are validated before use."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters are properly type-annotated with their expected types.  The return type is also clearly specified as `Dict[str, Any]`. The function does not use `**kwargs` parameters."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is largely complete and functional, correctly handling most input parameters and raising the documented exceptions.  The core logic of creating a simulated watch channel and storing it in the `DB` is implemented.  However, there's a minor gap: the docstring mentions validating the `pageToken` format, but the validation only checks if it's parsable as an integer.  A more robust check against a real page token format (if one exists in the context of the simulated Google Drive API) would be necessary for a fully complete implementation.  Additionally, error handling around database interactions could be improved by catching more specific exceptions and providing more informative error messages.  Finally, while deprecated parameters are handled with warnings, the logic for handling conflicting parameters (e.g., `driveId` and `teamDriveId`) could be more concise and clearer."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `watch` function does not handle phone numbers or email addresses as input.  Its parameters are all related to Google Drive API configuration for setting up a watch notification channel.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        }
      }
    },
    "gdrive/Replies.py": {
      "functions": {
        "create": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments and their types, including the nested structure of the `body` dictionary and the optional `author` field within it. The `Returns` section correctly details the structure of the returned dictionary, including nested structures. The `Raises` section lists the potential exceptions.  Types are specified for all parameters and return values."
          },
          "pydantic_usage": {
            "status": "Partially Used",
            "notes": "The function uses Pydantic's `BodyInputModel` (although the definition is not shown) to validate the `body` parameter.  However, `fileId` and `commentId` are validated using basic type checking (`isinstance`), not a Pydantic model.  Using Pydantic models for all three parameters would provide a more consistent and potentially more robust validation approach, allowing for more complex validation rules (e.g., string length constraints, regular expressions) to be easily defined.  The current validation is sufficient for basic type checking but lacks the expressiveness and maintainability of a Pydantic model-based approach."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function demonstrates good input validation for the `fileId`, `commentId`, and `body` parameters.  `fileId` and `commentId` are correctly checked for string type using `isinstance`.  `body` is checked for `None`, and if present, for being a dictionary.  Furthermore, it leverages Pydantic's `BodyInputModel` for comprehensive validation of the nested structure and data types within the `body` dictionary, including checking for required fields ('content') and handling optional fields ('author').  This catches missing keys and type mismatches within the nested dictionary."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `commentId`, `body`) are properly type-annotated with their expected types.  The return type is also clearly specified as `Dict[str, Any]`. The function does not use `**kwargs`.  Complex types like `Dict[str, Any]` and `Optional[Dict[str, str]]` within the `body` parameter are correctly specified."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the creation of a reply based on the provided input.  All functional input parameters (`fileId`, `commentId`, `body`) are used.  The function handles the documented exceptions (`TypeError`, `ValueError`, `PydanticValidationError`). There are no TODOs, pass statements, or placeholder implementations. The logic is complete and functional, utilizing the global `DB` as expected. The docstring accurately reflects the function's behavior, including return types and raised exceptions.  The use of Pydantic for validation is a good practice."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code does not handle phone numbers or email addresses as input.  The `body` dictionary can contain an email address within the nested `author` dictionary, but there's no normalization or validation performed on it. The function relies on a `BodyInputModel` (presumably from a Pydantic library) for validation, but the details of that model are not shown.  While Pydantic can handle email validation, the code itself doesn't directly perform any phone number processing.  Therefore, the rating is \"Not Applicable\" because the core functionality of the function doesn't involve phone number or email address processing.  To receive a different rating, the code would need to explicitly handle these data types and include the relevant normalization and validation steps."
          }
        },
        "delete": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a clear description of the function's purpose: deleting a reply.  It accurately documents the three arguments (`fileId`, `commentId`, `replyId`) with their types and descriptions. The `Args` section is well-structured. The `Returns` section correctly indicates that the function returns `None`.  Type hints are used consistently."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function `delete` does not use Pydantic models or any other form of input validation for its functional parameters (`fileId`, `commentId`, and `replyId`).  Before accessing the `DB`, these parameters should be validated to ensure they are strings and potentially check for other constraints (e.g., length, format, existence in the DB).  Adding Pydantic models would significantly improve the robustness of this function by providing type checking and data validation."
          },
          "input_validation": {
            "status": "Minimal",
            "notes": "The function performs no input validation on any of its functional parameters (`fileId`, `commentId`, `replyId`).  Before accessing `DB['users'][userId]['replies'].pop(replyId, None)`,  it should check if `replyId` is a valid key within the nested dictionary structure.  It also lacks type checking to ensure that `fileId`, `commentId`, and `replyId` are strings.  No checks are performed for empty strings or `None` values.  No error handling is present to catch potential `KeyError` exceptions if the `replyId` does not exist."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, commentId, replyId) are properly type-annotated as strings.  The return type is correctly specified as None.  The function does not use **kwargs."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly deletes a reply from the user's replies list in the global `DB`.  The `fileId` and `commentId` parameters are not used in the function's logic, making them unused functional parameters.  While the core delete functionality works, the lack of usage of these parameters suggests a potential incompleteness in the design or a misunderstanding of the required inputs.  The docstring accurately reflects the function's behavior, aside from the unused parameters."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `delete` does not handle any phone numbers or email addresses.  Its purpose is to delete a reply from a database given file, comment, and reply IDs. Therefore, the criteria of phone number normalization and email validation are irrelevant and not applicable to this function."
          }
        },
        "get": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and mostly accurate.  It clearly explains the function's purpose, arguments, return value, and exceptions.  The default value for `includeDeleted` is correctly documented.  The `Args` and `Returns` sections are comprehensive, including detailed descriptions of the dictionary structures.  The `Raises` section accurately lists the exceptions.  Types are specified for all parameters and the return value using type hints."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual type checking and validation for all functional input parameters (`fileId`, `commentId`, `replyId`, and `includeDeleted`).  While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing approach is sufficient and correctly handles type and emptiness checks.  Using Pydantic would not significantly improve the code in this specific case, given its simplicity."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on all three functional input parameters (`fileId`, `commentId`, and `replyId`).  Each is checked for correct type (string) using `isinstance` and for non-empty values.  The `includeDeleted` parameter is also correctly validated as a boolean.  Appropriate `TypeError` and `ValidationError` exceptions are raised with informative messages for invalid inputs.  All functional parameters are validated before being used in subsequent logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, commentId, replyId, includeDeleted) are properly type-annotated with their expected types (str, str, str, bool respectively).  The function's return type is clearly specified as Optional[Dict[str, Any]]. No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly retrieves a reply based on the provided `fileId`, `commentId`, and `replyId`.  All functional input parameters (`fileId`, `commentId`, `replyId`, `includeDeleted`) are used appropriately in the logic.  The documented exceptions (`TypeError` and `ValidationError`) are correctly implemented. There are no TODOs, pass statements, or placeholder implementations. The function's logic is complete and functional given the global `DB` dictionary. The docstring accurately reflects the function's behavior, including the return type and handling of deleted replies."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get` does not handle any phone number or email address inputs.  Its purpose is to retrieve a reply from a database given file, comment, and reply IDs.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function does include robust input validation for the IDs it *does* use, ensuring they are strings and not empty."
          }
        },
        "list": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose.  It accurately describes the function's arguments, including their types and default values. The `Returns` section is detailed, correctly specifying the dictionary structure and nested types, although it could benefit from explicitly mentioning the `fileId` and `commentId` keys within the `replies` list items (which are present in the implementation but missing in the docstring).  The `Raises` section correctly lists the potential exceptions.  The docstring is mostly consistent with the implementation."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for all functional parameters (fileId, commentId, includeDeleted, pageSize, pageToken).  It checks types and constraints such as string emptiness and positive integer values. While Pydantic could provide a more concise and potentially more robust way to perform this validation, the existing manual checks are comprehensive for this specific function.  Using Pydantic would be an improvement in terms of code readability and maintainability, but it's not strictly necessary given the existing validation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "All functional input parameters (`fileId`, `commentId`, `includeDeleted`, `pageSize`, `pageToken`) are checked for their correct data types.  `fileId` and `commentId` undergo comprehensive validation, checking for emptiness, whitespace, and ensuring they are strings without spaces. `pageSize` is validated to ensure it's a positive integer.  Appropriate `TypeError` and `ValidationError` exceptions are raised with informative messages for invalid inputs.  All functional parameters are validated before being used in subsequent logic."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (fileId, commentId, includeDeleted, pageSize, pageToken) are properly type-annotated with their expected types (str, str, Optional[bool], Optional[int], Optional[str] respectively).  The function's return type is clearly specified as Dict[str, Any].  The function does not use **kwargs parameters.  Complex types like Optional, List, and Dict are used correctly in the annotations."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional, correctly using all functional input parameters (`fileId`, `commentId`, `includeDeleted`, `pageSize`, `pageToken`).  The exception handling for `TypeError` and `ValidationError` is implemented correctly.  The pagination logic, while functional, uses a potentially fragile approach of converting `pageToken` to an integer without robust error handling (it silently defaults to 0 on error).  A more robust approach would be to either raise an error if the `pageToken` is invalid or use a more sophisticated token generation/parsing mechanism.  The docstring accurately reflects the function's behavior and return type.  The function also correctly handles the case where `author` information is missing from the reply data, providing default values.  However, the `_ensure_user` function is not defined within the provided code, and its absence could lead to unexpected behavior.  Finally, the `modifiedTime` is defaulted to `createdTime` if it's missing, which might not always be the desired behavior."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `list` does not handle any phone number or email address inputs.  Its inputs are file IDs, comment IDs, booleans, integers, and strings representing pagination tokens.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses solely on retrieving and paginating comment replies from a database (presumably represented by the `DB` variable)."
          }
        },
        "update": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a decent overview of the function's purpose.  It accurately describes the arguments, including their types and the structure of the nested dictionaries within the `body` argument. The `Returns` section correctly details the structure of the dictionary that is returned.  The docstring correctly mentions the optional `body` parameter and its default value (implicitly as an empty dictionary).  All types are specified."
          },
          "pydantic_usage": {
            "status": "Missing Validation",
            "notes": "The function lacks any input validation using Pydantic models or other methods for the functional parameters `fileId`, `commentId`, `replyId`, and the `body` dictionary and its nested fields.  While type hints are present, they are not enforced.  The code only checks if `body` is `None` and if a reply exists in the DB, but it doesn't validate the structure or content of `body` or the types of `fileId`, `commentId`, and `replyId`.  Using Pydantic models would significantly improve the robustness of the function by enforcing data types and structure, preventing unexpected errors caused by invalid input."
          },
          "input_validation": {
            "status": "Partial",
            "notes": "The function performs some input validation but is incomplete."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`fileId`, `commentId`, `replyId`, `body`) are properly type-annotated with their expected types (str, str, str, Optional[Dict[str, Any]]).  The function's return type is also clearly specified as `Optional[Dict[str, Any]]`.  The function does not use `**kwargs`.  Complex types like `Dict` and `Optional` are correctly used in the type annotations."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function correctly updates a reply in the global `DB` if it exists.  The `fileId` and `commentId` parameters are not used in the function's logic, making them effectively unused functional parameters.  The function's logic is otherwise complete and functional given the use of the global `DB`. The docstring accurately reflects the function's behavior and return type."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `update` function does not handle phone numbers or email addresses as input.  The `body` dictionary can contain an email address within the `author` dictionary, but the function doesn't perform any validation or normalization on it.  There's no processing or checking of the email's format or any phone number related data.  Therefore, the criteria for phone number normalization and email validation are not applicable."
          }
        }
      }
    }
  },
  "project_level": {
    "gdrive": {
      "project_structure": {
        "status": "Mostly Complete",
        "notes": "The project structure is largely sound and follows modern best practices.  All three main folders (`SimulationEngine`, `tests`, and the root API folder) are present and contain the core required files.  The `SimulationEngine` folder has all the essential components (`db.py`, `models.py`, `custom_errors.py`, `error_config.json`, and `error_definitions.json`). The `tests` folder is well-populated with numerous test files and contains the `__init__.py` file."
      }
    }
  }
}
{
  "analysis_timestamp": "2025-08-13T12:09:57.790991Z",
  "results": {
    "copilot/code_intelligence.py": {
      "functions": {
        "semantic_search": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and behavior within the context of an MCP server.  It accurately describes the natural language search functionality and how it handles different workspace sizes. The Args, Returns, and Raises sections are well-structured and informative.  Types are specified for all parameters and the return value.  The documentation of the dictionary structure within the return value is particularly thorough, clearly outlining each key, its type, and its meaning."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function `semantic_search` has only one functional input parameter: `query`.  The code performs input validation on `query` by explicitly checking if it's a non-empty string using `if not query or not isinstance(query, str):`. This manual check is sufficient for this simple input validation need.  Using a Pydantic model would add unnecessary complexity for this specific case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `semantic_search` has only one functional input parameter: `query`.  The validation for this parameter is comprehensive. It checks for both the data type (using `isinstance`) and the value (checking for emptiness using `not query`).  A `ValidationError` is raised with a clear message if the validation fails.  All aspects of type, value, and null/empty checks are present for the single functional input."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `semantic_search` has excellent parameter design and type annotations.  The single parameter `query` is correctly type-annotated as `str`. The return type is clearly specified as `List[Dict[str, Any]]`.  No `**kwargs` are used.  Complex types within the return type annotation are also correctly specified."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely implements its intended functionality.  The `query` parameter is correctly used.  All documented exceptions (`WorkspaceNotAvailableError`, `SearchFailedError`, `ValidationError`) are handled. There are no TODOs, pass statements, or obvious placeholders. The docstring accurately reflects the return type and structure."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `semantic_search` function does not handle phone numbers or email addresses as input.  Its input is a natural language query string used for code search within a workspace.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function focuses on other aspects of code search, such as file system traversal, content processing, and LLM interaction for relevance scoring."
          }
        },
        "list_code_usages": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'list_code_usages': def list_code_usages(file_path: str, line_number: int, column_number: int) -> List[Dict[str, Any]]:\n    \"\"\"Requests to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc.\n\n    This function lists all usages (e.g., references, definitions, implementations) of a specified code symbol such as a function, class, method, or variable.\n    It is used for purposes such as:\n    1. Looking for a sample implementation of an interface or class.\n    2. Checking how a function is used throughout the codebase.\n    3. Including and updating all usages when changing a function, method, or constructor.\n\n    Args:\n        file_path (str): The absolute path to the file containing the symbol for which usages are to be found.\n        line_number (int): The 1-based line number in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n        column_number (int): The 1-based column number (character offset) on the line in the specified file where the symbol is located. This typically refers to the start of the symbol's identifier.\n\n    Returns:\n        List[Dict[str, Any]]: A list of code usages found for the specified symbol. Each dictionary in the list represents a single usage and includes the following keys:\n            file_path (str): The path to the file where the usage is found.\n            start_line (int): The 1-based starting line number of the usage in the file.\n            end_line (int): The 1-based ending line number of the usage in the file.\n            start_column (Optional[int]): The 1-based starting column number (character offset) of the usage. Null if this information is not available or not applicable.\n            end_column (Optional[int]): The 1-based ending column number (character offset) of the usage. Null if this information is not available or not applicable.\n            usage_type (str): The type of code usage (e.g., 'reference', 'definition', 'implementation').\n            snippet (str): A short code snippet (typically one or a few lines) illustrating the usage in its context.\n\n    Raises:\n        SymbolNotFoundError: If no symbol is found at the specified 'file_path', 'line_number', and 'column_number', or if the identified element is not a symbol for which usages can be determined (e.g., a comment).\n        IndexingNotCompleteError: If the codebase is not yet fully indexed, preventing usage lookups. The client may retry after a delay.\n        InvalidInputError: If 'file_path', 'line_number', or 'column_number' are missing, malformed (e.g., non-existent file path, non-positive line/column numbers), or point to a location outside the bounds of the file content.\n        ProjectConfigurationError: If there is an issue with the project configuration that prevents resolving the file path.\n    \"\"\"\n    # 1. Initial Input Validation\n    if not file_path:\n        raise custom_errors.InvalidInputError(\"File path cannot be empty.\")\n    if not isinstance(line_number, int) or line_number <= 0:\n        raise custom_errors.InvalidInputError(\"Line number must be positive.\")\n    if not isinstance(column_number, int) or column_number <= 0:\n        raise custom_errors.InvalidInputError(\"Column number must be positive.\")\n\n    # 1.5 Check for relative path when cwd is not configured\n    if not os.path.isabs(file_path) and 'cwd' not in DB:\n        raise custom_errors.InvalidInputError(\"Current working directory is not configured.\")\n\n    # 2. Path Normalization and File Existence/Type Validation\n    try:\n        abs_file_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    file_entry = utils.get_file_system_entry(abs_file_path)\n    if not file_entry:\n        raise custom_errors.InvalidInputError(f\"File not found: {abs_file_path}\")\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.InvalidInputError(f\"Path is a directory, not a file: {abs_file_path}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n    if not isinstance(content_lines, list):\n        raise custom_errors.InvalidInputError(f\"File content is not in expected format: {abs_file_path}\")\n\n    # 3. Validate line and column numbers\n    num_lines = len(content_lines)\n    if num_lines == 0:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} (0 lines).\")\n    if line_number > num_lines:\n        raise custom_errors.InvalidInputError(\n            f\"Line number {line_number} is out of bounds for file {abs_file_path} ({num_lines} lines).\")\n\n    line_content = content_lines[line_number - 1]\n    line_length = len(line_content.rstrip('\\n'))\n    if column_number > line_length:\n        raise custom_errors.InvalidInputError(\n            f\"Column number {column_number} is out of bounds for line {line_number} in file {abs_file_path} (length {line_length}).\")\n\n    # 4. Check Indexing Status\n    if DB.get('code_indexing_status') != 'complete':\n        raise custom_errors.IndexingNotCompleteError(\"Codebase indexing is not yet complete. Please try again later.\")\n\n    # 5. Get symbol usages from index\n    code_symbols_index = DB.get('code_symbols_index', {})\n    if abs_file_path not in code_symbols_index:\n        raise custom_errors.SymbolNotFoundError(f\"No symbol data available for file {abs_file_path}.\")\n\n    # 6. Find the symbol at the given location\n    symbol_key = f\"{line_number}:{column_number}\"\n    if symbol_key not in code_symbols_index[abs_file_path]:\n        # Check if the location is a comment or whitespace\n        line_content = content_lines[line_number - 1]\n        if line_content.strip().startswith('#'):\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        if not line_content.strip():\n            raise custom_errors.SymbolNotFoundError(\n                f\"Element at {abs_file_path}:{line_number}:{column_number} is not a symbol (e.g., comment or whitespace).\")\n        raise custom_errors.SymbolNotFoundError(f\"No symbol found at {abs_file_path}:{line_number}:{column_number}.\")\n\n    # 7. Return the usages\n    symbol_data = code_symbols_index[abs_file_path][symbol_key]\n    return symbol_data.get(\"usages\", [])\n\n\n"
          }
        },
        "grep_search": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  It accurately describes the search functionality, limitations (20 results), and intended use cases. The `Args` and `Returns` sections are well-structured, clearly specifying types and descriptions.  The nested dictionary structure within the return value is adequately documented, listing all keys and their types. The `Raises` section correctly lists the potential exceptions.  Type hints are used consistently throughout the docstring."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `search_pattern` parameter. It checks if the input is a string and if it's not empty.  While Pydantic could be used, the current validation is sufficient and straightforward for this single parameter.  Using Pydantic would add unnecessary complexity for this simple case."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function `grep_search` performs good input validation on its single functional parameter, `search_pattern`.  It checks that `search_pattern` is a string (`isinstance` check) and that it's not empty.  It also handles potential `re.error` exceptions during regular expression compilation, raising a custom `InvalidSearchPatternError` with a descriptive message.  However, it lacks validation for the content of the search pattern beyond being non-empty.  For example, it doesn't check for overly long patterns that could lead to performance issues or denial-of-service attacks.  While the existing checks are valuable, more robust validation of the `search_pattern` content would improve the function's security."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `grep_search` has excellent parameter design.  It has one parameter, `search_pattern`, which is correctly type-annotated as `str`. The return type is also clearly specified as `List[Dict[str, Any]]`.  No `**kwargs` are used.  Complex types like `List` and `Dict` are properly specified."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements a text search within a workspace, using a regular expression to find matches.  It handles the documented exceptions (`ValidationError`, `WorkspaceNotAvailableError`, `InvalidSearchPatternError`) appropriately. The `search_pattern` parameter is fully utilized. The function limits results to 20 as specified, skips directories and excluded paths, and correctly formats the output dictionary.  The docstring accurately reflects the function's behavior and return type. There are no placeholders or TODOs.  The logic is complete and functional given the use of the global `DB` dictionary."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `grep_search` function does not handle phone numbers or email addresses as input.  Its purpose is to search for a given string or regular expression pattern within a file system.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        }
      }
    },
    "copilot/file_system.py": {
      "functions": {
        "file_search": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the `file_search` function's purpose and usage within an MCP server context.  It accurately describes the function's core functionality: searching for files using a glob pattern within a workspace, limited to 20 results. The examples provided are helpful and illustrative.  The Args, Returns, and Raises sections are well-structured and informative, correctly listing the types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function `file_search` uses manual input validation for the `glob_pattern` parameter. It checks if the input is a string, if it's empty, and if it's a valid glob pattern using `fnmatch.translate`.  While Pydantic could be used, the current manual validation is sufficient and arguably more readable in this specific case.  No other functional parameters exist requiring validation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `file_search` performs comprehensive validation of its single functional input parameter, `glob_pattern`.  It checks for the correct data type (string) using `isinstance`, and it validates that the string is not empty.  Furthermore, it uses `fnmatch.translate` within a `try-except` block to catch and handle potential `re.error` exceptions arising from invalid glob pattern syntax.  This demonstrates both type and value validation, ensuring the input is a well-formed glob pattern before proceeding.  All aspects of the input are validated before it's used in the file search operation."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `file_search` has an excellent parameter design.  The single parameter `glob_pattern` is correctly type-annotated as `str`. The return type is clearly specified as `List[str]`.  No `**kwargs` are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely implements its intended functionality.  It correctly handles input validation, searches the file system based on the provided glob pattern, limits results to 20, and raises the documented exceptions. The use of `fnmatch` and the handling of brace expansion in glob patterns are appropriate.  The logic for handling relative paths and ensuring files are within the workspace root is comprehensive, although somewhat complex.  The sorting of `file_system.keys()` ensures deterministic results, which is beneficial for testing."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided Python function `file_search` does not handle any phone numbers or email addresses.  Its purpose is to search for files within a workspace using glob patterns.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function's input is a glob pattern string, and its output is a list of file paths.  It correctly handles input validation for the glob pattern itself, raising appropriate exceptions for invalid inputs."
          }
        },
        "read_file": {
          "docstring_quality": {
            "status": "Excellent",
            "notes": "The docstring is comprehensive and well-written.  It clearly explains the function's purpose, accurately describes the arguments and return values including their types and nested structures (especially the complex `file_details` dictionary), and lists all possible exceptions. The description of the optional `outline` within `file_details` is particularly helpful.  The docstring effectively communicates how the function handles partial file reads and provides sufficient detail for a user to understand its behavior and limitations.  There are no inconsistencies between the docstring and the implementation; the docstring accurately reflects the function's logic, including the handling of edge cases like empty files and various error conditions.  The detailed explanation of the `file_details` dictionary structure, including the `is_truncated_at_top` and `is_truncated_at_bottom` flags, is exemplary."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function `read_file` performs input validation on `file_path`, `start_line`, and `end_line` using type checking and manual range checks.  While Pydantic could be used to structure this validation more concisely, the existing approach is sufficient and covers all functional input parameters.  The current method is arguably more readable in this specific case than an equivalent Pydantic model would be.  There's no need for Pydantic here given the existing robust validation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on all three functional input parameters (`file_path`, `start_line`, `end_line`)."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`file_path`, `start_line`, `end_line`) are properly type-annotated with their expected types (str, int, int). The function's return type is clearly specified as `Dict[str, Any]`.  No **kwargs parameters are used.  Complex types within the return dictionary are also properly specified using type annotations (Dict, List, Optional)."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is largely complete and functional, correctly handling file reading, various exceptions (FileNotFoundError, InvalidLineRangeError, PermissionDeniedError, InvalidInputError, RuntimeError), and returning a dictionary matching the docstring's specification.  The logic for handling edge cases like empty files and line ranges beyond the file's length appears mostly correct.  However, there's a minor gap: the `outline` parameter in the `file_details` dictionary is retrieved from the DB but isn't explicitly used or processed within the function's logic beyond being included in the return value.  While this doesn't break functionality, it suggests a potential area for improvement or future extension.  The function correctly uses all functional input parameters (`file_path`, `start_line`, `end_line`)."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided `read_file` function does not process or handle phone numbers or email addresses.  Its purpose is to read a specified range of lines from a file and return the content along with metadata.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        },
        "list_dir": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and behavior.  It accurately describes the function's role in listing directory contents within the context of an MCP server. The Args, Returns, and Raises sections are well-structured and informative.  Types are specified for parameters and return values.  The description of the dictionary structure in the Returns section is comprehensive, detailing all keys and their types."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function `list_dir` has only one functional input parameter, `path`.  Pydantic models are not used for its validation. However, the function performs type checking (`isinstance(path, str)`) and extensive manual validation to ensure the path is valid, exists, and points to a directory.  This manual validation is sufficient and covers all aspects of the input. Using Pydantic wouldn't add significant value in this case, as the existing checks are clear, comprehensive, and directly handle the specific error conditions."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `list_dir` performs comprehensive validation of its single functional input parameter, `path`.  It checks:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `list_dir` has excellent parameter design and type annotations.  The single parameter `path` is correctly type-annotated as `str`. The return type `List[Dict[str, Any]]` is also clearly specified.  No `**kwargs` are used.  Complex types like `List` and `Dict` are properly specified."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the functionality described in its docstring.  It handles the `path` input parameter correctly, validating its type and using it to access and process data from the global `DB`. All documented exceptions (`DirectoryNotFoundError`, `PermissionDeniedError`, `InvalidInputError`) are properly handled and raised in appropriate scenarios. The function's logic is complete, and there are no TODOs, placeholders, or pass statements. The return value matches the docstring's description, providing a list of dictionaries with the specified keys (\"name\", \"type\", \"path\").  The results are sorted by name as promised."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code is for listing the contents of a directory. It does not handle or process phone numbers or email addresses.  Therefore, the criteria of phone number normalization and email validation are not applicable. The function focuses solely on file system operations and path handling."
          }
        },
        "insert_edit_into_file": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose,  how to format the input (`edit_instructions`), and what to expect in the output. The Args, Returns, and Raises sections are well-structured and informative.  Types are specified for all parameters and the return value.  The example provided is helpful in illustrating the expected format of `edit_instructions`."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function performs input validation using type checking and manual checks for empty strings.  While it doesn't use Pydantic models, the validation is comprehensive for the three functional input parameters (`file_path`, `edit_instructions`, `explanation`).  Using Pydantic models would add some overhead without significantly improving the clarity or robustness of the existing validation.  The current approach is sufficient and clearly communicates the expected input types and constraints."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive input validation on all three functional parameters: `file_path`, `edit_instructions`, and `explanation`."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`file_path`, `edit_instructions`, `explanation`) are properly type-annotated with their expected types (str). The function's return type is clearly specified as `Dict[str, Any]`.  No **kwargs parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is largely implemented and functional, correctly handling most error conditions and using all functional input parameters (`file_path`, `edit_instructions`, `explanation`).  The logic for rewriting the file using an LLM is present and attempts to handle various potential errors from the LLM call.  The return value matches the docstring's specification."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `insert_edit_into_file` does not handle phone numbers or email addresses as input.  Its purpose is to edit files based on instructions provided as strings.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function focuses on file system operations and interaction with an LLM for code generation, not data validation of contact information."
          }
        }
      }
    },
    "copilot/command_line.py": {
      "functions": {
        "run_in_terminal": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  It accurately describes the function's core functionality: executing shell commands in a persistent terminal environment, handling background processes, and managing pager issues.  The description of the `is_background` parameter and its implications for return values is clear.  The Args, Returns, and Raises sections are comprehensive, listing all parameters, return values, and exceptions.  Types are specified correctly for parameters and the return value.  The documentation of the dictionary return value is detailed, specifying all keys and their types (though the `Any` type for some values is a bit broad)."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function `run_in_terminal` uses only one functional input parameter: `command` (str) and `is_background` (bool).  Input validation for `command` is performed manually: it checks if the command string is empty or whitespace only.  The `is_background` parameter is a boolean and its type is implicitly checked by Python.  While Pydantic could be used, the existing manual validation is sufficient for this function's needs.  Adding Pydantic would add complexity without significant benefit given the simplicity of the input validation requirements."
          },
          "input_validation": {
            "status": "Good",
            "notes": "The function `run_in_terminal` performs good input validation on the `command` parameter.  It checks for null/empty strings and whitespace-only strings using `not command or command.isspace()`. It also performs further validation by attempting to parse the command using `shlex.split` and raising an `InvalidInputError` if parsing fails or results in an empty argument list. This addresses null/empty checks and special constraints related to command parsing.  Appropriate exceptions (`InvalidInputError`, `CommandExecutionError`, `TerminalNotAvailableError`) are raised with informative messages for various failure scenarios."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "All function parameters (`command`, `is_background`) are properly type-annotated with their expected types (`str`, `bool`). The function's return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` parameters are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely implements its intended functionality: running shell commands in a terminal, handling background processes, and managing the current working directory.  The `command` and `is_background` parameters are used correctly.  Exception handling is present for `InvalidInputError`, `TerminalNotAvailableError`, and `CommandExecutionError`, although the handling of unexpected exceptions could be improved by providing more specific error messages. The docstring accurately reflects the function's behavior and return values."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `run_in_terminal` does not handle or process phone numbers or email addresses.  Its purpose is to execute shell commands, and it does not include any logic for input normalization or validation of those data types.  Therefore, the criteria for phone number normalization and email validation are not applicable to this function."
          }
        },
        "get_terminal_output": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and provides a comprehensive overview of the function's purpose, arguments, return values, and exceptions.  It accurately reflects the function's behavior in most aspects."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `terminal_id` parameter.  It checks the type, emptiness, and whether it contains only digits.  While Pydantic could be used, the existing validation is sufficient and clear.  Using Pydantic wouldn't significantly improve this specific validation task, and might add unnecessary complexity for this simple case."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get_terminal_output` performs comprehensive validation on its single functional input parameter, `terminal_id`.  It checks for the correct data type (string) using `isinstance`, checks for empty or whitespace-only strings, and validates that the string contains only digits using `isdigit`.  Each validation failure raises an appropriate custom exception with a clear error message.  All possible invalid input scenarios for `terminal_id` are handled."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get_terminal_output` has excellent parameter design.  The single parameter, `terminal_id`, is properly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` are used.  All type annotations are complete and accurate."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly retrieves output and status information for a given terminal ID.  All functional input parameters (`terminal_id`) are used.  All documented exceptions (`TypeError`, `InvalidInputError`, `InvalidTerminalIdError`, `OutputRetrievalError`) are handled. There are no TODO comments, pass statements, or placeholder implementations. The logic is complete and functional, considering the use of the global `DB` dictionary. The docstring accurately reflects the function's behavior, return type, and exception handling.  The function correctly handles both running and finished processes, including cleanup and error conditions."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get_terminal_output` does not handle phone numbers or email addresses.  Its input is a `terminal_id`, which is validated as a string containing only digits. This validation ensures the integrity of the `terminal_id` within the context of the function's purpose (managing background processes), but it's not related to phone number or email address processing.  Therefore, the criteria of phone number normalization and email validation are not applicable."
          }
        }
      }
    },
    "copilot/vscode_environment.py": {
      "functions": {
        "get_vscode_api": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and mostly accurate.  It clearly explains the function's purpose, how it's used within the context of VS Code extension development, and the structure of its return value.  The Args, Returns, and Raises sections are comprehensive and well-formatted.  Types are consistently specified for parameters and return values.  The nested dictionary structure within the return value is thoroughly documented, including keys, types, and descriptions.  The docstring also correctly highlights the potential exceptions."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses type checking (`isinstance`) and manual validation (checking string length, emptiness, and specific keywords) to validate the `query` input.  While Pydantic could provide a more structured and potentially more concise way to perform these checks, the existing validation is sufficient and covers all aspects of the input.  Using Pydantic would be an improvement in terms of code readability and maintainability, but it's not strictly necessary for the functionality."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get_vscode_api` performs comprehensive validation of its single functional input parameter, `query`.  It checks that `query` is a string (`isinstance(query, str)`), that it's not empty or whitespace-only (`not cleaned_query`), that it doesn't contain specific \"too broad\" terms (case-insensitive check), and that its length meets a minimum threshold (`len(cleaned_query) < _MIN_QUERY_LEN_FOR_API_SEARCH`).  Appropriate exceptions (`ValidationError`, `QueryTooBroadError`) are raised with informative error messages for each validation failure.  All possible scenarios of invalid input for the `query` parameter are handled."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get_vscode_api` has excellent parameter design and type annotations.  The single parameter `query` is correctly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  There is no use of `**kwargs`.  Complex types within the return dictionary are also properly specified using `List` and `Dict`."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the described functionality.  It uses the `query` input parameter effectively for searching the `api_data` obtained from the global `DB`. All documented exceptions (`QueryTooBroadError`, `APIDatabaseNotAvailableError`, `ValidationError`) are properly handled and raised under the appropriate conditions.  The function's logic is complete and functional, correctly handling various scenarios such as empty queries, short queries, and malformed entries in the `api_data`. The return value matches the docstring's description, providing a dictionary with a list of API references containing the specified keys. There are no placeholders, TODO comments, or pass statements.  The input validation ensures that the `query` is a string.  The function efficiently handles potential issues with the `api_data` structure and content, ensuring data integrity."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get_vscode_api` does not handle phone numbers or email addresses as input.  Its input is a string representing a query for VS Code API documentation. Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function focuses solely on querying and processing a text-based API database."
          }
        },
        "install_extension": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose, arguments, return value, and exceptions.  The description clearly explains the function's role in a new workspace creation process within the context of an MCP server.  The `Args` and `Returns` sections are well-structured and informative, including type hints and detailed descriptions.  The `Raises` section accurately lists all potential exceptions.  The documentation of the dictionary returned is thorough, specifying keys, types, and even providing examples."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `extension_id` parameter.  It checks the type, emptiness, and format of the string. While Pydantic could provide a more structured and potentially more concise way to perform this validation, the existing manual checks are sufficient and cover all aspects of the input.  Using Pydantic would be an improvement in terms of code readability and maintainability, but it's not strictly necessary given the existing validation."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `install_extension` performs comprehensive validation of its single functional input parameter, `extension_id`.  It checks:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `install_extension` has excellent parameter design.  The single parameter `extension_id` is correctly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` are used."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is mostly complete and functional, correctly using the `extension_id` parameter.  It handles the documented exceptions (`ExtensionNotFoundError`, `InstallationFailedError`, `UsageContextError`, `ValidationError`). The docstring accurately reflects the return type and behavior.  However, the \"simulated installation\" logic is overly simplistic and relies on a pre-defined dictionary (`DB[\"extensions_simulated_install_behavior\"]`) to determine success or failure.  A more robust implementation might involve mocking a more realistic installation process, potentially including error scenarios beyond a simple \"success\" or \"failure\".  The current implementation also lacks handling for unexpected errors during the simulated installation, which could lead to silent failures or unexpected behavior.  While the function is functional within its simulated environment, a more comprehensive approach to error handling and simulation would improve its completeness."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `install_extension` does not handle any phone numbers or email addresses.  Its input is a VS Code extension ID, which is validated for format (publisher.name) but not for phone number or email-related aspects.  Therefore, the categories of phone number normalization and email validation are not applicable."
          }
        }
      }
    },
    "copilot/project_setup.py": {
      "functions": {
        "create_new_workspace": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose, aligning well with its role in an MCP server context.  It clearly explains the function's purpose, the input (`query`), and the expected output (a dictionary with \"query,\" \"summary,\" and \"steps\"). The `Args` and `Returns` sections are well-structured and informative, including type hints.  The `Raises` section accurately lists the potential exceptions.  The documentation of the dictionary structure in the `Returns` section is particularly helpful, specifying the types and nested structures of the \"steps\" list."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses a simple `if` statement to validate that the `query` parameter is a non-empty string.  This is sufficient validation for this single input parameter.  While a Pydantic model could be used, it's not strictly necessary for this level of validation.  The existing approach is clear, concise, and effective."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `create_new_workspace` has only one functional input parameter: `query`.  The validation for this parameter is comprehensive.  It checks that `query` is of type `str` and that it is not an empty string after stripping whitespace using `query.strip()`.  An appropriate `custom_errors.ValidationError` is raised with a clear error message if the validation fails.  All aspects of type and value validation are covered for the single functional input."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `create_new_workspace` has excellent parameter design.  The single parameter `query` is properly type-annotated as `str`. The return type is clearly specified as `Dict[str, Any]`.  No `**kwargs` are used.  Complex types within the return dictionary are also properly annotated (List and Dict)."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function is largely complete and functional, correctly handling the `query` parameter and using it to generate a project creation plan via an LLM call.  Exception handling for `ValidationError`, `WorkspaceNotAvailableError`, and `RuntimeError` is implemented as documented.  The logic for parsing the LLM response and structuring the output dictionary is also present. However, the comment `# Further validation could check if workspace_root_path exists in DB['file_system'] and is a directory.` indicates a missing validation step. While the current implementation relies on tests to ensure a valid `workspace_root`, adding this validation would improve robustness.  Additionally, error handling could be improved by providing more specific error messages to the user, rather than just generic error messages."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `create_new_workspace` does not handle phone numbers or email addresses as input.  Its input is a string representing a user query for creating a new workspace.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function.  The function focuses solely on processing a text-based query to generate a project creation plan, and its input validation is limited to checking if the query is a non-empty string."
          }
        },
        "get_project_setup_info": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose and usage within an MCP server context.  It accurately describes the function's inputs and outputs, including the structure of the dictionary return value.  The `Args` and `Returns` sections are well-written and detailed, specifying types and providing clear explanations.  The `Raises` section comprehensively lists all potential exceptions.  Type hints are used consistently throughout the docstring."
          },
          "pydantic_usage": {
            "status": "Not Needed",
            "notes": "The function uses manual input validation for the `project_type` and `language` parameters.  It checks that they are strings and that they are not empty. While Pydantic could provide a more concise and potentially more feature-rich validation approach (e.g., allowing for regular expression-based validation of the string content), the existing manual checks adequately cover the basic validation needs for these parameters.  The use of Pydantic would be an improvement in terms of code readability and maintainability, but the current validation is not deficient."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function performs comprehensive validation on both functional input parameters, `project_type` and `language`.  Both are checked for correct data type (string) and for being non-empty strings.  Appropriate `ValidationError` exceptions are raised with clear error messages for invalid inputs.  All functional input parameters are validated before use."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "Both function parameters, `project_type` and `language`, are properly type-annotated as `str`.  The return type is clearly specified as `Dict[str, Any]`.  The function does not use `**kwargs`.  All type annotations are complete and accurately reflect the expected types."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly implements the logic described in its docstring.  It validates the input parameters (`project_type` and `language`), handles the `WorkspaceNotInitializedError`, `ProjectTypeOrLanguageNotFoundError`, and `ConfigurationError` exceptions as documented.  It uses both functional input parameters (`project_type` and `language`) effectively to retrieve and return the appropriate setup information from the `_PROJECT_SETUP_DATA` dictionary (presumably populated elsewhere).  There are no placeholders, TODO comments, or pass statements. The returned dictionary structure matches the docstring's description, and appropriate type checking is performed to ensure the data structure integrity.  The error handling is robust, providing informative error messages."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `get_project_setup_info` does not handle phone numbers or email addresses as input.  Its inputs are `project_type` and `language`, both strings representing project characteristics.  Therefore, the criteria of phone number normalization and email validation are not applicable.  The function focuses on validating the input types and retrieving project setup information from a database (`DB.get()` and `utils._PROJECT_SETUP_DATA`)."
          }
        },
        "create_new_jupyter_notebook": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is well-written and provides a comprehensive overview of the function's purpose, behavior, and potential exceptions.  It accurately describes the function's role in creating a new Jupyter Notebook within a VS Code environment, explaining its utility within the context of an MCP server.  The Returns section clearly outlines the dictionary structure, including key names and types. The Raises section correctly lists the potential exceptions.  The description of the function's purpose is clear and concise.  Type hints are used consistently throughout the docstring."
          },
          "pydantic_usage": {
            "status": "Not Applicable",
            "notes": "The function `create_new_jupyter_notebook` does not take any input parameters.  All data it uses comes from the global `DB` object or internal calculations. Therefore, the question of input validation using Pydantic or other methods is not applicable."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `create_new_jupyter_notebook` has no explicit input parameters.  All its operations rely on data retrieved from the global `DB` object (`workspace_root`, `cwd`). The code performs comprehensive validation on these implicitly received inputs:"
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `create_new_jupyter_notebook` has no parameters.  The return type is clearly specified as `Dict[str, Any]`.  There is no use of `**kwargs`."
          },
          "implementation_status": {
            "status": "Fully Implemented",
            "notes": "The function correctly creates a new Jupyter Notebook file in the specified directory, handling potential errors such as invalid paths, existing files, and workspace configuration issues.  It uses the `workspace_root` and `cwd` information from the global `DB` to determine the target directory.  The exception handling is comprehensive, raising the documented `FileCreationError` and `JupyterEnvironmentError` exceptions where appropriate.  The function generates unique filenames to avoid conflicts and includes a safety mechanism to prevent infinite loops. The docstring accurately reflects the function's behavior and return value.  There are no placeholders or TODO comments.  All functional parameters are used (there are no functional parameters in this function). The function successfully adds the newly created notebook's metadata to the in-memory file system represented by the global `DB`."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided function `create_new_jupyter_notebook` does not handle any phone number or email address inputs.  Its purpose is to create a new Jupyter Notebook file, dealing solely with file paths and directory management.  Therefore, the criteria of phone number normalization and email validation are not applicable to this function."
          }
        }
      }
    },
    "copilot/code_quality_version_control.py": {
      "functions": {
        "get_errors": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'get_errors': def get_errors(file_path: str) -> List[Dict[str, Any]]:\n    \"\"\"Get any compile or lint errors in a code file.\n\n    If a user mentions errors or problems in a file, they may be referring to\n    these compile or lint errors. This function allows seeing the same errors\n    that the user is seeing. It is also used after editing a file to validate\n    the change.\n\n    Args:\n        file_path (str): The path to the code file to analyze for errors.\n\n    Returns:\n        List[Dict[str, Any]]: A list of compile or lint errors found in the\n            specified code file. Each dictionary in the list represents an\n            error and contains the following keys:\n            file_path (str): The path to the file where the error occurred.\n            line_number (int): The line number (1-based) where the error\n                is located.\n            column_number (Optional[int]): The column number (1-based) where\n                the error starts, if available.\n            message (str): The descriptive error message provided by the\n                compiler or linter.\n            severity (str): The severity of the issue (e.g., 'error',\n                'warning', 'info').\n            code (Optional[str]): An optional error code or identifier\n                (e.g., 'E0425', 'eslint(no-unused-vars)').\n            source (Optional[str]): The source of the error (e.g., 'compiler',\n                'linter:eslint', 'typescript-language-server').\n\n    Raises:\n        FileNotFoundError: If the specified file path does not exist.\n        ToolConfigurationError: If the linter, compiler, or language server\n            required to get errors is not configured correctly, not found,\n            or fails to run.\n        AnalysisFailedError: If analysis of the file could not be completed\n            for other reasons.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # Validate input type early for better error messages\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"File path must be a string.\")\n\n    if not file_path:\n        raise custom_errors.ValidationError(\"File path cannot be empty.\")\n\n    try:\n        file_path_abs = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        # Path is outside workspace or otherwise invalid for get_absolute_path\n        raise custom_errors.FileNotFoundError(\n            f\"File path is invalid or outside the workspace: {file_path}. Detail: {e}\")\n\n    file_entry = utils.get_file_system_entry(file_path_abs)\n\n    if file_entry is None:\n        # This will catch cases where get_absolute_path succeeds but the file isn't in DB\n        raise custom_errors.FileNotFoundError(f\"File not found: {file_path_abs}\")\n\n    if file_entry.get(\"is_directory\", False):\n        raise custom_errors.AnalysisFailedError(f\"Path is a directory, not a file: {file_path_abs}\")\n\n    content_lines = file_entry.get(\"content_lines\", [])\n\n    # Check if content is a placeholder indicating it's unanalyzable\n    # The utils._is_content_uneditable_placeholder helper checks for binary, large file, or read error placeholders.\n    uneditable_reason = utils._is_content_uneditable_placeholder(content_lines)\n    if uneditable_reason is not None:\n        raise custom_errors.AnalysisFailedError(\n            f\"Cannot analyze file {file_path}: content {uneditable_reason}.\"\n        )\n\n    # --- START FIX: Prioritize simulated_diagnostics from DB ---\n    # If simulated_diagnostics exist for this file, return them directly.\n    # This allows tests to pre-define errors without triggering mock generation.\n    simulated_diagnostics = file_entry.get(\"simulated_diagnostics\")\n    if simulated_diagnostics is not None:\n        if simulated_diagnostics == \"TOOL_CONFIG_ERROR\":\n            raise custom_errors.ToolConfigurationError(\n                f\"Tool configuration error for file: {file_path_abs}\"\n            )\n        elif simulated_diagnostics == \"ANALYSIS_FAILED_ERROR\":\n            raise custom_errors.AnalysisFailedError(\n                f\"Analysis failed for file: {file_path_abs}\"\n            )\n        return simulated_diagnostics\n\n    errors: List[Dict[str, Any]] = []\n    _, file_ext_lower = os.path.splitext(file_path_abs)\n    file_ext_lower = file_ext_lower.lower()\n\n    # Dispatch to specific mock error generators based on file extension\n    try:\n        if file_ext_lower == \".py\":\n            py_errors = _get_mock_python_errors(file_path_abs, content_lines)\n            if py_errors is not None:  # Make sure errors list is not None\n                errors.extend(py_errors)\n        elif file_ext_lower == \".js\":\n            js_errors = _get_mock_javascript_errors(file_path_abs, content_lines)\n            if js_errors is not None:  # Make sure errors list is not None\n                errors.extend(js_errors)\n        elif file_ext_lower == \".ts\":\n            ts_errors = _get_mock_typescript_errors(file_path_abs, content_lines)\n            if ts_errors is not None:  # Make sure errors list is not None\n                errors.extend(ts_errors)\n        elif file_ext_lower == \".json\":\n            json_errors = _get_mock_json_errors(file_path_abs, content_lines)\n            if json_errors is not None:  # Make sure errors list is not None\n                errors.extend(json_errors)\n        else:\n            # For extensions not explicitly handled, check if they are known code/lintable types\n            # for which a tool might be expected.\n            general_lintable_extensions = {\n                \".java\", \".c\", \".cpp\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\", \".kt\",\n                \".xml\", \".yaml\", \".yml\", \".html\", \".htm\", \".css\", \".scss\", \".less\", \".md\",\n                \".sh\", \".bash\", \".ps1\", \".R\", \".sql\", \".pl\", \".lua\"\n            }\n            # Extensions for which we have specific handlers above\n            handled_extensions = {\".py\", \".js\", \".ts\", \".json\"}\n\n            if file_ext_lower in general_lintable_extensions and file_ext_lower not in handled_extensions:\n                # Don't catch this specific error - let it propagate to the caller\n                raise custom_errors.ToolConfigurationError(\n                    f\"No linter or compiler is configured in this environment for file type '{file_ext_lower}'.\"\n                )\n    except custom_errors.ToolConfigurationError:\n        # Re-raise ToolConfigurationError to ensure it's properly propagated\n        raise\n    except Exception as e:\n        # If any other error happens during error detection, log it but return what we have so far\n        # This ensures the function is resilient against internal errors\n        print_log(f\"Warning: Error occurred during error detection: {str(e)}\")\n    \n    # Always return a list (empty or with errors)\n    return errors\n\n\n"
          }
        },
        "get_changed_files": {
          "docstring_quality": {
            "status": "Good",
            "notes": "The docstring is present and provides a good overview of the function's purpose: retrieving git diffs for changed files.  It accurately describes the function's core functionality and its role in an MCP server context (implicitly, by mentioning git repository operations). The Returns section clearly outlines the structure of the returned list of dictionaries, including the keys and their types.  The Raises section correctly lists the potential exceptions.  Type hints are used effectively (`-> List[Dict[str, Any]]`)."
          },
          "pydantic_usage": {
            "status": "Not Applicable",
            "notes": "The function `get_changed_files` does not take any input parameters.  Therefore, the question of input validation using Pydantic or other methods is not applicable."
          },
          "input_validation": {
            "status": "Comprehensive",
            "notes": "The function `get_changed_files` does not take any functional input parameters.  All its operations rely on executing git commands and parsing their output. Therefore, the question of input parameter validation is not applicable in this specific context.  The code does robustly handle errors during git command execution and parsing, raising appropriate exceptions with informative messages."
          },
          "function_parameters": {
            "status": "Excellent",
            "notes": "The function `get_changed_files` has no parameters.  The return type is clearly specified as `List[Dict[str, Any]]`.  There is no use of `**kwargs`.  Therefore, all criteria for an \"Excellent\" rating are met."
          },
          "implementation_status": {
            "status": "Mostly Complete",
            "notes": "The function largely fulfills its purpose of retrieving changed files and their diffs from a Git repository.  Exception handling for `GitRepositoryNotFoundError` and `GitCommandError` is implemented correctly, covering various failure scenarios. The docstring accurately reflects the function's return type and behavior.  However, the handling of file statuses is incomplete; it ignores statuses like 'T' (type change) and 'U' (unmerged). While these are noted as ignored,  a more robust implementation might include them or at least provide a more informative message about which statuses are being omitted.  Additionally, the error messages could be slightly improved for better clarity and user experience (e.g., more specific error messages in `GitCommandError`)."
          },
          "input_normalization": {
            "status": "Not Applicable",
            "notes": "The provided code is a Python function designed to retrieve git diffs for changed files in a repository.  It does not handle or process any phone numbers or email addresses.  Therefore, the criteria of phone number normalization and email validation are not applicable. The function focuses solely on interacting with the git command-line interface and parsing its output."
          }
        }
      }
    },
    "copilot/test_file_management.py": {
      "functions": {
        "test_search": {
          "docstring_quality": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          },
          "pydantic_usage": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          },
          "input_validation": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          },
          "function_parameters": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          },
          "implementation_status": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          },
          "input_normalization": {
            "status": "Error",
            "notes": "Could not find or read function 'test_search': def test_search(file_path: str) -> Dict[str, Any]:\n    \"\"\"For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.\n\n    This function processes a given `file_path`. If `file_path` points to a source code file, the function searches for the file containing its tests.\n    Conversely, if `file_path` points to a test file, the function searches for the file containing the code under test.\n    The outcome of this search, including the path to the related file (if found), the type of relationship, and a confidence score, is returned.\n\n    Args:\n        file_path (str): The absolute path to the source code file or test file for which to find its related counterpart.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing details of the identified related file with the following keys:\n            input_file_path (str): The path of the input file (either source or test) for which a related file was searched.\n            related_file_path (Optional[str]): The path to the corresponding test file (if input was source) or source file (if input was test). Null if no confidently related file is found.\n            relationship_type (Optional[str]): Describes the identified relationship, e.g., 'test_file_for_source' or 'source_file_for_test'. Null if no related file is found.\n            confidence_score (Optional[float]): A score between 0.0 and 1.0 indicating the confidence in the match, if applicable and calculable. Null otherwise.\n\n    Raises:\n        FileNotFoundError: If the input file path provided in `file_path` does not exist in the workspace.\n        ProjectConfigurationError: If project configuration or conventions needed to determine test/source relationships are missing, ambiguous, or invalid.\n        SearchLogicError: If an internal error occurs within the test search logic.\n        ValidationError: If input arguments fail validation.\n    \"\"\"\n    # --- Input Validation ---\n    if not isinstance(file_path, str):\n        raise custom_errors.ValidationError(\"Input 'file_path' must be a string\")\n    if not file_path:  # Check after type check\n        raise custom_errors.ValidationError(\"Input 'file_path' cannot be empty\")\n\n    # --- Configuration Checks ---\n    workspace_root_from_db = DB.get(\"workspace_root\")\n    if not workspace_root_from_db:\n        raise custom_errors.ProjectConfigurationError(\"Workspace root is not configured.\")\n\n    normalized_workspace_root = utils._normalize_path_for_db(workspace_root_from_db)\n\n    # --- Path Resolution and Initial Validation ---\n    abs_input_path: str\n    try:\n        abs_input_path = utils.get_absolute_path(file_path)\n    except ValueError as e:\n        raise custom_errors.ProjectConfigurationError(str(e)) from e\n\n    try:\n        if not utils.path_exists(abs_input_path):\n            raise custom_errors.FileNotFoundError(f\"File not found: {abs_input_path}\")\n\n        if not utils.is_file(abs_input_path):\n            raise custom_errors.ProjectConfigurationError(\n                f\"Input path must be a file, not a directory: {abs_input_path}\")\n    except (AttributeError, TypeError) as e:\n        raise custom_errors.SearchLogicError(\n            f\"Internal error processing file system data for path {abs_input_path}\"\n        ) from e\n\n    # --- Core Logic ---\n    input_filename = os.path.basename(abs_input_path)\n    input_file_dir_abs = utils._normalize_path_for_db(os.path.dirname(abs_input_path))\n\n    module_details = extract_module_details(input_filename)\n\n    is_input_test_by_name = module_details[\"is_test_by_name\"]\n    is_input_in_test_dir = is_in_test_dir(input_file_dir_abs, normalized_workspace_root)\n\n    is_input_likely_test = is_input_test_by_name or is_input_in_test_dir\n\n    module_name_for_matching = module_details[\"base_module_name\"]\n    current_ext = module_details[\"ext\"]\n\n    potential_candidates: List[Tuple[str, float]] = []\n    relationship_type: Optional[str] = None\n\n    if is_input_likely_test:\n        relationship_type = \"source_file_for_test\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=False, workspace_root_abs=normalized_workspace_root\n            )\n    else:\n        relationship_type = \"test_file_for_source\"\n        if module_name_for_matching:\n            potential_candidates = generate_related_file_candidates(\n                input_file_dir_abs, module_name_for_matching, current_ext,\n                is_searching_for_test_file=True, workspace_root_abs=normalized_workspace_root\n            )\n\n    valid_matches: List[Tuple[str, float]] = []\n    for cand_path, conf in potential_candidates:\n        try:\n            if cand_path != abs_input_path and utils.path_exists(cand_path) and utils.is_file(cand_path):\n                valid_matches.append((cand_path, conf))\n        except (AttributeError, TypeError):\n            pass\n\n    valid_matches.sort(key=lambda x: x[1], reverse=True)\n\n    result: Dict[str, Any] = {\n        \"input_file_path\": abs_input_path,\n        \"related_file_path\": None,\n        \"relationship_type\": None,\n        \"confidence_score\": None,\n    }\n\n    if valid_matches:\n        best_match_path, best_confidence = valid_matches[0]\n        result[\"related_file_path\"] = utils._normalize_path_for_db(best_match_path)\n        result[\"relationship_type\"] = relationship_type\n        result[\"confidence_score\"] = best_confidence\n\n    if result[\"related_file_path\"] is None:\n        result[\"relationship_type\"] = None\n\n    return result\n"
          }
        }
      }
    }
  },
  "project_level": {
    "copilot": {
      "project_structure": {
        "status": "Mostly Complete",
        "notes": "The project structure is largely sound, adhering to the modern requirements.  All three main folders (`SimulationEngine`, `tests`, and the root API folder) are present and contain the core required files.  The `SimulationEngine` folder has all the essential components (`db.py`, `models.py`, `custom_errors.py`, `error_config.json`, etc.). The `tests` folder is well-organized with numerous test files."
      }
    }
  }
}